{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import zarr\n",
    "import allel\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zarr2LDNe\n",
    " \n",
    "       Sanjay C Nagi      06/07/20\n",
    "\n",
    "I have written a snakemake pipeline which subsets and downsamples the zarr genotype arrays in phase 2, and runs LDNe on the populations within. I now want to run this on all of phase 3. As phase 3 is grouped by sample_set, I want to run LDNe on all locations + years that have greater than 15 samples, though this number is currently arbitrary.\n",
    "\n",
    "Which groups of samples do we want to run LDNe on? see below...\n",
    "### Phase 3 samples for LDNe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "manifest = pd.read_csv(\"../../data/phase3/Ag1000g.phase3.manifest.tsv\", sep=\"\\t\")\n",
    "#manifest[manifest.n_samples >= 15]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The idea here would be to (in snakemake) loop through each sample_set (not shown above), then within each sample set loop through each location and finally year, where there is temporal samples. \n",
    "\n",
    "At each point we need to extract the appropriate genotypes from the sample set zarrs. We'll also need to filter SNPs, and then can run the downstream LDNe prep."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "manifest = pd.read_csv(\"../../data/phase3/Ag1000g.phase3.manifest.full.tsv\", sep=\"\\t\")\n",
    "manifest.location = [loc.replace(\" \", \"\") for loc in manifest.location]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Phase 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_sets = manifest.sample_set.unique()\n",
    "\n",
    "chroms = ['3L','3R']\n",
    "n = 20000\n",
    "argsgff = \"../data/An.gambiae-PEST-BASEFEATURES_agamP4.12.gff3.gz\"\n",
    "\n",
    "local_path = Path(\"/home/sanj/ag1000g/data/phase3/\").expanduser() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As phase 3 is organised into sample sets, I will loop through each sample set, and each location within that, each year within that, each species, producing FSTAT format files for LDNe, and writing out metadata along the way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### functions #####\n",
    "\n",
    "def ld_prune(gn, size, step, threshold=.2, n_iter=1, blen=10000):\n",
    "    \n",
    "    gn_alt = gn.to_n_alt()\n",
    "\n",
    "    for i in range(n_iter):\n",
    "        loc_unlinked = allel.locate_unlinked(gn_alt, size=size, step=step, threshold=threshold, blen=blen)\n",
    "        n = np.count_nonzero(loc_unlinked)\n",
    "        n_remove = gn.shape[0] - n\n",
    "        print('iteration', i+1, 'retaining', n, 'removing', n_remove, 'variants')\n",
    "        gn = gn.compress(loc_unlinked, axis=0)\n",
    "    return(gn, loc_unlinked)\n",
    "    \n",
    "\n",
    "def replace_with_dict2_generic(ar, dic, assume_all_present=False):\n",
    "    # Extract out keys and values\n",
    "    k = np.array(list(dic.keys()))\n",
    "    v = np.array(list(dic.values()))\n",
    "\n",
    "    # Get argsort indices\n",
    "    sidx = k.argsort()\n",
    "\n",
    "    ks = k[sidx]\n",
    "    vs = v[sidx]\n",
    "    idx = np.searchsorted(ks,ar)\n",
    "\n",
    "    if assume_all_present==0:\n",
    "        idx[idx==len(vs)] = 0\n",
    "        mask = ks[idx] == ar\n",
    "        return np.where(mask, vs[idx], ar)\n",
    "    else:\n",
    "        return vs[idx]\n",
    "    \n",
    "def load_arrays_noncoding_and_centromeres(local_path, _set, chrom, coding_reg_df, sitefilter='gamb_colu', filter_centro=True):\n",
    "    \n",
    "    \"\"\"\n",
    "    This function reads and filters a genotyping array to the noncoding, noncentromeric regions, and applys a filter depending on \n",
    "    whether the samples are arabiensis (arab) or gambiae/coluzzii (gamb_colu)\n",
    "    \"\"\"\n",
    "    Ag_array = zarr.open_array(f\"{local_path}/snp_genotypes/all/{_set}/{chrom}/calldata/GT/\", mode = 'r')\n",
    "    filters = zarr.open(f\"{local_path}/site_filters/dt_20200416/{sitefilter}/{chrom}/variants/filter_pass\", mode=\"r\")\n",
    "    positions = zarr.open_array(f\"{local_path}/snp_genotypes/all/sites/{chrom}/variants/POS/\", mode='r')\n",
    "    positions = positions[:][filters[:]]    \n",
    "    geno = allel.GenotypeDaskArray(Ag_array)\n",
    "    geno = geno[filters[:]]\n",
    "    \n",
    "    if filter_centro is True:\n",
    "        if chrom == '2L':\n",
    "            centromere = (positions > 3000000)\n",
    "        elif chrom == '2R':\n",
    "            centromere = (positions < 57000000)\n",
    "        elif chrom == '3L':\n",
    "            centromere = (positions > 2000000)\n",
    "        elif chrom == '3R':\n",
    "            centromere = (positions < 50000000)\n",
    "        elif chrom == 'X':\n",
    "            centromere = (positions < 21000000) \n",
    "            \n",
    "        positions = allel.SortedIndex(positions[centromere])\n",
    "    else:\n",
    "        positions = allel.SortedIndex(positions)\n",
    "        \n",
    "    #get boolean array for positions that are coding - allel.locate_ranges so fast!\n",
    "    coding = positions.locate_ranges(coding_reg_df.start, coding_reg_df.end, strict=False)\n",
    "    #compress to get noncoding SNPs and remove centromeric regions of low recombination\n",
    "    #get non-centromeric regions. currently chosen by eye based on ag1000g phase1 paper fig1.\n",
    "  \n",
    "    if filter_centro is True: geno = geno.compress(centromere, axis=0)\n",
    "    geno = geno.compress(~coding, axis=0) #we want noncoding regions so '~' to get inverse of boolean\n",
    "    positions = positions[~coding]\n",
    "    \n",
    "    return(geno, positions)\n",
    "\n",
    "\n",
    "def maf_filter(gn, flt=0.05):\n",
    "    freqs = gn.count_alleles().to_frequencies().compute()\n",
    "    ALT1 = freqs[:,1] > flt\n",
    "    ALT2 = freqs[:,2] > flt\n",
    "    ALT3 = freqs[:,3] > flt\n",
    "    maf_flt = np.logical_or(ALT1, ALT2, ALT3)\n",
    "    gn = gn.compress(maf_flt, axis=0)\n",
    "    \n",
    "    return(gn, maf_flt)\n",
    "\n",
    "def convert2dat(gn, positions, n, _set, loc, yr, sp, chrom):\n",
    "    \n",
    "    \"\"\"\n",
    "    This function takes a genotyping array and positions, along with info on the sample_set, location , year, species, chrom,\n",
    "    and converts the genotyping array into a .dat file, suitable for use with LDNe. It randomly downsamples the genotyping array\n",
    "    by n SNPs\n",
    "    \"\"\"\n",
    "\n",
    "    # Biallelic and MAF 0.05 filter\n",
    "    ac = gn.count_alleles()\n",
    "    bial_ = ac.is_biallelic()\n",
    "    gn = gn.compress(bial_, axis=0)\n",
    "\n",
    "    gn, maf_flt = maf_filter(gn, 0.05)\n",
    "    \n",
    "    ## LD pruning\n",
    "    print(f\"GenotypeArray shape before pruning - {gn.shape}\")\n",
    "    gnu, loc_unlinked = ld_prune(gn, size=500, step=250, threshold=.2, n_iter=1, blen=10000)\n",
    "\n",
    "    #take random sample of n SNPs\n",
    "    if gnu.shape[0] < n:\n",
    "        snp_sample = np.random.choice(gnu.shape[0], gnu.shape[0], replace=False)\n",
    "    else :\n",
    "        snp_sample = np.random.choice(gnu.shape[0], n, replace=False)\n",
    "    \n",
    "    snp_sample.sort()\n",
    "    gnr = np.array(gnu[snp_sample][:])\n",
    "    gnr = gnr.astype(str)\n",
    "    \n",
    "    pos = positions[bial_]\n",
    "    pos = pos[maf_flt]\n",
    "    pos = pos[loc_unlinked]\n",
    "    pos = pos[snp_sample]\n",
    "    prefix = f'{chrom}_'\n",
    "    pos_string = [prefix + p for p in pos.astype(str)]\n",
    "\n",
    "    gnr[gnr == '-1'] = '00' #convert missing alleles \n",
    "    dat = np.empty([gnr.shape[0], gnr.shape[1]])\n",
    "\n",
    "    #join genotypes in same individual \n",
    "    print(f\"Converting to .dat {_set} {loc} {yr} {sp} {chrom}\")\n",
    "    for x in range(gnr.shape[0]):\n",
    "        for y in range(gnr.shape[1]):\n",
    "            dat[x,y] = ''.join(gnr[x,y])\n",
    "\n",
    "    #convert to .dat format genotypes \n",
    "    dat = dat.astype(str)\n",
    "    dat_convert_dict = {'0.0':'0101',\n",
    "                        '1.0':'0102',\n",
    "                        '2.0':'0103',\n",
    "                        '3.0':'0104',\n",
    "                        '10.0':'0201',\n",
    "                        '11.0':'0202',\n",
    "                        '12.0':'0203',\n",
    "                        '13.0':'0204',\n",
    "                        '20.0':'0301',\n",
    "                        '21.0':'0302',\n",
    "                        '22.0':'0303',\n",
    "                        '23.0':'0304',\n",
    "                        '30.0':'0401',\n",
    "                        '31.0':'0402',\n",
    "                        '32.0':'0403',\n",
    "                        '33.0':'0404'}\n",
    "    ## convert values to FSTAT .dat format\n",
    "    dat = replace_with_dict2_generic(dat, dat_convert_dict, assume_all_present=False)\n",
    "    \n",
    "    #stack population name and transposed genotypes \n",
    "    popnames = np.repeat(f\"{_set}{loc}{yr}{sp}{chrom}\", gnr.shape[1])\n",
    "    dat = np.column_stack((popnames, dat.T)) #\n",
    "    \n",
    "    #write out .dat file for LDNe \n",
    "    with open(f'../data/dat/{_set}.{loc}.{yr}.{sp}.{chrom}.dat', 'w') as datfile:\n",
    "        datfile.write(f'{gnr.shape[1]}\\t{gnr.shape[0]}\\t4\\t2\\n')\n",
    "        datfile.write(\"\\n\".join(\"\".join(map(str, x)) for x in pos_string)) \n",
    "        datfile.write(\"\\n\")\n",
    "        datfile.write(\"\\n\".join(\"\\t\".join(map(str, x)) for x in dat))\n",
    "\n",
    "def convert2dattemporal(gn1, gn2, pos1, pos2, n, loc, yr1, yr2, chrom):\n",
    "    \"\"\"\n",
    "    This function takes two genotyping arrays and positions, along with info on the sample_set, location , year, species, chrom,\n",
    "    and converts the arrays into a .dat file, suitable for use with the NeEstimator temporal estimator. It randomly downsamples the genotyping array\n",
    "    by n SNPs\n",
    "    \"\"\"\n",
    "    print(f\"-----  converting zarr to dat for {loc} {yr1} {yr2} {chrom} ------\")\n",
    "    # Biallelic and MAF 0.05 filter\n",
    "    bial_ = gn1.count_alleles().is_biallelic()\n",
    "    gn1 = gn1.compress(bial_, axis=0)\n",
    "    gn2 = gn2.compress(bial_, axis=0)\n",
    "    pos1 = pos1[bial_]\n",
    "    pos2 = pos2[bial_]\n",
    "\n",
    "    gn1, maf_flt1 = maf_filter(gn1, 0.05)\n",
    "    pos1 = pos1[maf_flt1]\n",
    "    gn2, maf_flt2 = maf_filter(gn2, 0.05)\n",
    "    pos2 = pos2[maf_flt2]   \n",
    "\n",
    "    ## LD pruning\n",
    "    print(f\"GenotypeArray shape before pruning - {gn1.shape}\")\n",
    "    gnu1, loc_unlinked = ld_prune(gn1, size=500, step=250, threshold=.2, n_iter=1, blen=10000)\n",
    "    pos1 = pos1[loc_unlinked]\n",
    "    gnu2, loc_unlinked = ld_prune(gn2, size=500, step=250, threshold=.2, n_iter=1, blen=10000)\n",
    "    pos2 = pos2[loc_unlinked]\n",
    "\n",
    "    # get intersection two pos arrays so that we have the same variants in both genotype arrays\n",
    "    pos1 = allel.SortedIndex(pos1)\n",
    "    pos2 = allel.SortedIndex(pos2)\n",
    "    bool1, bool2 = pos1.locate_intersection(pos2)\n",
    "\n",
    "    pos1 = pos1.compress(bool1)\n",
    "    pos2 = pos2.compress(bool2)\n",
    "\n",
    "    gnu1 = gnu1.compress(bool1, axis=0)\n",
    "    gnu2 = gnu2.compress(bool2, axis=0)\n",
    "    \n",
    "    assert gnu1.shape[0] == gnu2.shape[0], \"The two arrays have differing numbers of SNPs\"  \n",
    "    \n",
    "    #take random sample of n SNPs\n",
    "    if gnu1.shape[0] < n:\n",
    "        snp_sample = np.random.choice(gnu1.shape[0], gnu1.shape[0], replace=False)\n",
    "    else :\n",
    "        snp_sample = np.random.choice(gnu1.shape[0], n, replace=False)\n",
    "    \n",
    "    snp_sample.sort()\n",
    "    gnr1 = np.array(gnu1[snp_sample][:])\n",
    "    gnr2 = np.array(gnu2[snp_sample][:])\n",
    "    gnr1 = gnr1.astype(str)\n",
    "    gnr2 = gnr2.astype(str)\n",
    "    \n",
    "    # we only need one pos array from here as they are identical\n",
    "    pos = pos1[snp_sample]\n",
    "    prefix = f'{chrom}_'\n",
    "    pos_string = [prefix + p for p in pos.astype(str)]\n",
    "\n",
    "    gnr1[gnr1 == '-1'] = '00' #convert missing alleles \n",
    "    gnr2[gnr2 == '-1'] = '00' #convert missing alleles \n",
    "\n",
    "    dat1 = np.empty([gnr1.shape[0], gnr1.shape[1]])\n",
    "    dat2 = np.empty([gnr2.shape[0], gnr2.shape[1]])\n",
    "\n",
    "    #join genotypes in same individual \n",
    "    print(f\"Array one is of size {gnr1.shape} and array two is size {gnr2.shape}\")\n",
    "    print(f\"Converting to .dat {loc} {chrom} years {yr1} {yr2}\")\n",
    "    for x in range(gnr1.shape[0]):\n",
    "        for y in range(gnr1.shape[1]):\n",
    "            dat1[x,y] = ''.join(gnr1[x,y])\n",
    "\n",
    "    for x in range(gnr2.shape[0]):\n",
    "        for y in range(gnr2.shape[1]):\n",
    "            dat2[x,y] = ''.join(gnr2[x,y])\n",
    "            \n",
    "    #convert to .dat format genotypes \n",
    "    dat1 = dat1.astype(str)\n",
    "    dat2 = dat2.astype(str)\n",
    "\n",
    "    dat_convert_dict = {'0.0':'0101',\n",
    "                        '1.0':'0102',\n",
    "                        '2.0':'0103',\n",
    "                        '3.0':'0104',\n",
    "                        '10.0':'0201',\n",
    "                        '11.0':'0202',\n",
    "                        '12.0':'0203',\n",
    "                        '13.0':'0204',\n",
    "                        '20.0':'0301',\n",
    "                        '21.0':'0302',\n",
    "                        '22.0':'0303',\n",
    "                        '23.0':'0304',\n",
    "                        '30.0':'0401',\n",
    "                        '31.0':'0402',\n",
    "                        '32.0':'0403',\n",
    "                        '33.0':'0404'}\n",
    "    \n",
    "    ## convert values to FSTAT .dat format\n",
    "    dat1 = replace_with_dict2_generic(dat1, dat_convert_dict, assume_all_present=False)\n",
    "    dat2 = replace_with_dict2_generic(dat2, dat_convert_dict, assume_all_present=False)\n",
    "    \n",
    "    #stack population name and transposed genotypes \n",
    "    popname1 = np.repeat(f\"{loc}{yr1}{chrom}\", gnr1.shape[1])\n",
    "    dat1 = np.column_stack((popname1, dat1.T)) #\n",
    "    #stack population name and transposed genotypes \n",
    "    popname2 = np.repeat(f\"{loc}{yr2}{chrom}\", gnr2.shape[1])\n",
    "    dat2 = np.column_stack((popname2, dat2.T)) #\n",
    "    \n",
    "    #write out .dat file for LDNe \n",
    "    with open(f'../data/dat/temporal.{loc}.{yr1}.{yr2}.{chrom}.dat', 'w') as datfile:\n",
    "        datfile.write(f'{gnr1.shape[1]+gnr2.shape[1]}\\t{gnr1.shape[0]}\\t4\\t2\\n')\n",
    "        datfile.write(\"\\n\".join(\"\".join(map(str, x)) for x in pos_string)) \n",
    "        datfile.write(\"\\n\")\n",
    "        datfile.write(\"\\n\".join(\"\\t\".join(map(str, x)) for x in dat1))\n",
    "        datfile.write(\"\\n\")\n",
    "        datfile.write(\"\\n\".join(\"\\t\".join(map(str, x)) for x in dat2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------ LDNe_Ag -------------------------------\n",
      "\n",
      "Storing metadata in data/Phase3.LDNe.tsv\n",
      "\n",
      "Producing LDNe input for Bioko, 2002, gambiae, 3L. 10 individuals, (gambcolu filter)\n",
      "GenotypeArray shape before pruning - (370914, 10, 2)\n",
      "iteration 1 retaining 15426 removing 355488 variants\n",
      "Converting to .dat AG1000G-GQ Bioko 2002 gambiae 3L\n",
      "Writing .batch.txt file for LDNe...\n",
      "\n",
      "Producing LDNe input for Antula, 2010, gambiae, 3L. 15 individuals, (gambcolu filter)\n",
      "GenotypeArray shape before pruning - (468179, 15, 2)\n",
      "iteration 1 retaining 48151 removing 420028 variants\n",
      "Converting to .dat AG1000G-GW Antula 2010 gambiae 3L\n",
      "Writing .batch.txt file for LDNe...\n",
      "\n",
      "Producing LDNe input for Antula, 2010, intermediate, 3L. 45 individuals, (gambcolu filter)\n",
      "GenotypeArray shape before pruning - (423179, 45, 2)\n",
      "iteration 1 retaining 112829 removing 310350 variants\n",
      "Converting to .dat AG1000G-GW Antula 2010 intermediate 3L\n",
      "Writing .batch.txt file for LDNe...\n",
      "\n",
      "Producing LDNe input for Safim, 2010, intermediate, 3L. 27 individuals, (gambcolu filter)\n",
      "GenotypeArray shape before pruning - (464749, 27, 2)\n",
      "iteration 1 retaining 64181 removing 400568 variants\n",
      "Converting to .dat AG1000G-GW Safim 2010 intermediate 3L\n",
      "Writing .batch.txt file for LDNe...\n",
      "\n",
      "Producing LDNe input for Kilifi, 2012, arabiensis, 3L. 10 individuals, (arabiensis filter)\n",
      "GenotypeArray shape before pruning - (219726, 10, 2)\n",
      "iteration 1 retaining 13274 removing 206452 variants\n",
      "Converting to .dat AG1000G-KE Kilifi 2012 arabiensis 3L\n",
      "Writing .batch.txt file for LDNe...\n",
      "\n",
      "Producing LDNe input for Kilifi, 2012, intermediate, 3L. 45 individuals, (gambcolu filter)\n",
      "GenotypeArray shape before pruning - (261167, 45, 2)\n",
      "iteration 1 retaining 3383 removing 257784 variants\n",
      "Converting to .dat AG1000G-KE Kilifi 2012 intermediate 3L\n",
      "Writing .batch.txt file for LDNe...\n",
      "\n",
      "Producing LDNe input for Kilifi, 2012, gambiae, 3L. 9 individuals, (gambcolu filter)\n",
      "GenotypeArray shape before pruning - (281856, 9, 2)\n",
      "iteration 1 retaining 4162 removing 277694 variants\n",
      "Converting to .dat AG1000G-KE Kilifi 2012 gambiae 3L\n",
      "Writing .batch.txt file for LDNe...\n",
      "\n",
      "Producing LDNe input for Kilifi, 2000, gambiae, 3L. 19 individuals, (gambcolu filter)\n",
      "GenotypeArray shape before pruning - (454147, 19, 2)\n",
      "iteration 1 retaining 26616 removing 427531 variants\n",
      "Converting to .dat AG1000G-KE Kilifi 2000 gambiae 3L\n",
      "Writing .batch.txt file for LDNe...\n",
      "\n",
      "Producing LDNe input for Kababougou, 2014, coluzzii, 3L. 12 individuals, (gambcolu filter)\n",
      "GenotypeArray shape before pruning - (373905, 12, 2)\n",
      "iteration 1 retaining 33860 removing 340045 variants\n",
      "Converting to .dat AG1000G-ML-A Kababougou 2014 coluzzii 3L\n",
      "Writing .batch.txt file for LDNe...\n",
      "\n",
      "Producing LDNe input for Kababougou, 2014, gambiae, 3L. 28 individuals, (gambcolu filter)\n",
      "GenotypeArray shape before pruning - (438280, 28, 2)\n",
      "iteration 1 retaining 71831 removing 366449 variants\n",
      "Converting to .dat AG1000G-ML-A Kababougou 2014 gambiae 3L\n",
      "Writing .batch.txt file for LDNe...\n",
      "\n",
      "Producing LDNe input for Ouassorola, 2014, coluzzii, 3L. 9 individuals, (gambcolu filter)\n",
      "GenotypeArray shape before pruning - (710750, 9, 2)\n",
      "iteration 1 retaining 21918 removing 688832 variants\n",
      "Converting to .dat AG1000G-ML-A Ouassorola 2014 coluzzii 3L\n",
      "Writing .batch.txt file for LDNe...\n",
      "\n",
      "Producing LDNe input for Bancoumana, 2004, gambiae, 3L. 9 individuals, (gambcolu filter)\n",
      "GenotypeArray shape before pruning - (720083, 9, 2)\n",
      "iteration 1 retaining 22447 removing 697636 variants\n",
      "Converting to .dat AG1000G-ML-B Bancoumana 2004 gambiae 3L\n",
      "Writing .batch.txt file for LDNe...\n",
      "\n",
      "Producing LDNe input for Kela, 2004, gambiae, 3L. 23 individuals, (gambcolu filter)\n",
      "GenotypeArray shape before pruning - (399571, 23, 2)\n",
      "iteration 1 retaining 42457 removing 357114 variants\n",
      "Converting to .dat AG1000G-ML-B Kela 2004 gambiae 3L\n",
      "Writing .batch.txt file for LDNe...\n",
      "\n",
      "Producing LDNe input for Douna, 2004, coluzzii, 3L. 19 individuals, (gambcolu filter)\n",
      "GenotypeArray shape before pruning - (498937, 19, 2)\n",
      "iteration 1 retaining 69907 removing 429030 variants\n",
      "Converting to .dat AG1000G-ML-B Douna 2004 coluzzii 3L\n",
      "Writing .batch.txt file for LDNe...\n",
      "\n",
      "Producing LDNe input for Chikhwawa, 2015, arabiensis, 3L. 41 individuals, (arabiensis filter)\n",
      "GenotypeArray shape before pruning - (252315, 41, 2)\n",
      "iteration 1 retaining 47378 removing 204937 variants\n",
      "Converting to .dat AG1000G-MW Chikhwawa 2015 arabiensis 3L\n",
      "Writing .batch.txt file for LDNe...\n",
      "\n",
      "Producing LDNe input for Furvela, 2004, gambiae, 3L. 71 individuals, (gambcolu filter)\n",
      "GenotypeArray shape before pruning - (384790, 71, 2)\n",
      "iteration 1 retaining 26090 removing 358700 variants\n",
      "Converting to .dat AG1000G-MZ Furvela 2004 gambiae 3L\n",
      "Writing .batch.txt file for LDNe...\n",
      "\n",
      "Producing LDNe input for Muleba, 2015, arabiensis, 3L. 137 individuals, (arabiensis filter)\n",
      "GenotypeArray shape before pruning - (262957, 137, 2)\n",
      "iteration 1 retaining 90597 removing 172360 variants\n",
      "Converting to .dat AG1000G-TZ Muleba 2015 arabiensis 3L\n",
      "Writing .batch.txt file for LDNe...\n",
      "\n",
      "Producing LDNe input for Muleba, 2015, gambiae, 3L. 32 individuals, (gambcolu filter)\n",
      "GenotypeArray shape before pruning - (399197, 32, 2)\n",
      "iteration 1 retaining 67270 removing 331927 variants\n",
      "Converting to .dat AG1000G-TZ Muleba 2015 gambiae 3L\n",
      "Writing .batch.txt file for LDNe...\n",
      "\n",
      "Producing LDNe input for Moshi, 2012, arabiensis, 3L. 40 individuals, (arabiensis filter)\n",
      "GenotypeArray shape before pruning - (247758, 40, 2)\n",
      "iteration 1 retaining 44017 removing 203741 variants\n",
      "Converting to .dat AG1000G-TZ Moshi 2012 arabiensis 3L\n",
      "Writing .batch.txt file for LDNe...\n",
      "\n",
      "Producing LDNe input for Tarime, 2012, arabiensis, 3L. 47 individuals, (arabiensis filter)\n",
      "GenotypeArray shape before pruning - (268216, 47, 2)\n",
      "iteration 1 retaining 59507 removing 208709 variants\n",
      "Converting to .dat AG1000G-TZ Tarime 2012 arabiensis 3L\n",
      "Writing .batch.txt file for LDNe...\n",
      "\n",
      "Producing LDNe input for Muheza, 2013, gambiae, 3L. 36 individuals, (gambcolu filter)\n",
      "GenotypeArray shape before pruning - (430408, 36, 2)\n",
      "iteration 1 retaining 32756 removing 397652 variants\n",
      "Converting to .dat AG1000G-TZ Muheza 2013 gambiae 3L\n",
      "Writing .batch.txt file for LDNe...\n",
      "\n",
      "Producing LDNe input for Nagongera, 2012, arabiensis, 3L. 81 individuals, (arabiensis filter)\n",
      "GenotypeArray shape before pruning - (252641, 81, 2)\n",
      "iteration 1 retaining 76742 removing 175899 variants\n",
      "Converting to .dat AG1000G-UG Nagongera 2012 arabiensis 3L\n",
      "Writing .batch.txt file for LDNe...\n",
      "\n",
      "Producing LDNe input for Nagongera, 2012, gambiae, 3L. 112 individuals, (gambcolu filter)\n",
      "GenotypeArray shape before pruning - (363874, 112, 2)\n",
      "iteration 1 retaining 172286 removing 191588 variants\n",
      "Converting to .dat AG1000G-UG Nagongera 2012 gambiae 3L\n",
      "Writing .batch.txt file for LDNe...\n",
      "\n",
      "Producing LDNe input for Kihihi, 2012, gambiae, 3L. 95 individuals, (gambcolu filter)\n",
      "GenotypeArray shape before pruning - (390464, 95, 2)\n",
      "iteration 1 retaining 155062 removing 235402 variants\n",
      "Converting to .dat AG1000G-UG Kihihi 2012 gambiae 3L\n",
      "Writing .batch.txt file for LDNe...\n",
      "------------------------ LDNe_Ag -------------------------------\n",
      "\n",
      "Storing metadata in data/Phase3.LDNe.tsv\n",
      "\n",
      "Producing LDNe input for Luanda, 2009, coluzzii, 3R. 81 individuals, (gambcolu filter)\n",
      "GenotypeArray shape before pruning - (462740, 81, 2)\n",
      "iteration 1 retaining 60876 removing 401864 variants\n",
      "Converting to .dat AG1000G-AO Luanda 2009 coluzzii 3R\n",
      "Writing .batch.txt file for LDNe...\n",
      "\n",
      "Producing LDNe input for Pala, 2012, gambiae, 3R. 48 individuals, (gambcolu filter)\n",
      "GenotypeArray shape before pruning - (531382, 48, 2)\n",
      "iteration 1 retaining 164595 removing 366787 variants\n",
      "Converting to .dat AG1000G-BF-A Pala 2012 gambiae 3R\n",
      "Writing .batch.txt file for LDNe...\n",
      "\n",
      "Producing LDNe input for Pala, 2012, coluzzii, 3R. 11 individuals, (gambcolu filter)\n",
      "GenotypeArray shape before pruning - (452204, 11, 2)\n",
      "iteration 1 retaining 34870 removing 417334 variants\n",
      "Converting to .dat AG1000G-BF-A Pala 2012 coluzzii 3R\n",
      "Writing .batch.txt file for LDNe...\n",
      "\n",
      "Producing LDNe input for Bana, 2012, coluzzii, 3R. 42 individuals, (gambcolu filter)\n",
      "GenotypeArray shape before pruning - (469829, 42, 2)\n",
      "iteration 1 retaining 140917 removing 328912 variants\n",
      "Converting to .dat AG1000G-BF-A Bana 2012 coluzzii 3R\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing .batch.txt file for LDNe...\n",
      "\n",
      "Producing LDNe input for Bana, 2012, gambiae, 3R. 22 individuals, (gambcolu filter)\n",
      "GenotypeArray shape before pruning - (499457, 22, 2)\n",
      "iteration 1 retaining 52242 removing 447215 variants\n",
      "Converting to .dat AG1000G-BF-A Bana 2012 gambiae 3R\n",
      "Writing .batch.txt file for LDNe...\n",
      "\n",
      "Producing LDNe input for Souroukoudinga, 2012, coluzzii, 3R. 29 individuals, (gambcolu filter)\n",
      "GenotypeArray shape before pruning - (570995, 29, 2)\n",
      "iteration 1 retaining 99569 removing 471426 variants\n",
      "Converting to .dat AG1000G-BF-A Souroukoudinga 2012 coluzzii 3R\n",
      "Writing .batch.txt file for LDNe...\n",
      "\n",
      "Producing LDNe input for Souroukoudinga, 2012, gambiae, 3R. 28 individuals, (gambcolu filter)\n",
      "GenotypeArray shape before pruning - (584028, 28, 2)\n",
      "iteration 1 retaining 89667 removing 494361 variants\n",
      "Converting to .dat AG1000G-BF-A Souroukoudinga 2012 gambiae 3R\n",
      "Writing .batch.txt file for LDNe...\n",
      "\n",
      "Producing LDNe input for Bana, 2014, coluzzii, 3R. 47 individuals, (gambcolu filter)\n",
      "GenotypeArray shape before pruning - (503740, 47, 2)\n",
      "iteration 1 retaining 169518 removing 334222 variants\n",
      "Converting to .dat AG1000G-BF-B Bana 2014 coluzzii 3R\n",
      "Writing .batch.txt file for LDNe...\n",
      "\n",
      "Producing LDNe input for Bana, 2014, gambiae, 3R. 15 individuals, (gambcolu filter)\n",
      "GenotypeArray shape before pruning - (576270, 15, 2)\n",
      "iteration 1 retaining 64119 removing 512151 variants\n",
      "Converting to .dat AG1000G-BF-B Bana 2014 gambiae 3R\n",
      "Writing .batch.txt file for LDNe...\n",
      "\n",
      "Producing LDNe input for Pala, 2014, gambiae, 3R. 16 individuals, (gambcolu filter)\n",
      "GenotypeArray shape before pruning - (624937, 16, 2)\n",
      "iteration 1 retaining 67726 removing 557211 variants\n",
      "Converting to .dat AG1000G-BF-B Pala 2014 gambiae 3R\n",
      "Writing .batch.txt file for LDNe...\n",
      "\n",
      "Producing LDNe input for Souroukoudinga, 2014, gambiae, 3R. 15 individuals, (gambcolu filter)\n",
      "GenotypeArray shape before pruning - (577342, 15, 2)\n",
      "iteration 1 retaining 64862 removing 512480 variants\n",
      "Converting to .dat AG1000G-BF-B Souroukoudinga 2014 gambiae 3R\n",
      "Writing .batch.txt file for LDNe...\n",
      "\n",
      "Producing LDNe input for Monomtenga, 2004, gambiae, 3R. 13 individuals, (gambcolu filter)\n",
      "GenotypeArray shape before pruning - (523022, 13, 2)\n",
      "iteration 1 retaining 47068 removing 475954 variants\n",
      "Converting to .dat AG1000G-BF-C Monomtenga 2004 gambiae 3R\n",
      "Writing .batch.txt file for LDNe...\n",
      "\n",
      "Producing LDNe input for Gbadolite, 2015, gambiae, 3R. 76 individuals, (gambcolu filter)\n",
      "GenotypeArray shape before pruning - (492195, 76, 2)\n",
      "iteration 1 retaining 206228 removing 285967 variants\n",
      "Converting to .dat AG1000G-CD Gbadolite 2015 gambiae 3R\n",
      "Writing .batch.txt file for LDNe...\n",
      "\n",
      "Producing LDNe input for Bangui, 1994, gambiae, 3R. 53 individuals, (gambcolu filter)\n",
      "GenotypeArray shape before pruning - (483078, 53, 2)\n",
      "iteration 1 retaining 181219 removing 301859 variants\n",
      "Converting to .dat AG1000G-CF Bangui 1994 gambiae 3R\n",
      "Writing .batch.txt file for LDNe...\n",
      "\n",
      "Producing LDNe input for Bangui, 1994, coluzzii, 3R. 13 individuals, (gambcolu filter)\n",
      "GenotypeArray shape before pruning - (495618, 13, 2)\n",
      "iteration 1 retaining 44748 removing 450870 variants\n",
      "Converting to .dat AG1000G-CF Bangui 1994 coluzzii 3R\n",
      "Writing .batch.txt file for LDNe...\n",
      "\n",
      "Producing LDNe input for Tiassale, 2012, coluzzii, 3R. 80 individuals, (gambcolu filter)\n",
      "GenotypeArray shape before pruning - (508872, 80, 2)\n",
      "iteration 1 retaining 150041 removing 358831 variants\n",
      "Converting to .dat AG1000G-CI Tiassale 2012 coluzzii 3R\n",
      "Writing .batch.txt file for LDNe...\n",
      "\n",
      "Producing LDNe input for Mayos, 2009, gambiae, 3R. 110 individuals, (gambcolu filter)\n",
      "GenotypeArray shape before pruning - (469470, 110, 2)\n",
      "iteration 1 retaining 210556 removing 258914 variants\n",
      "Converting to .dat AG1000G-CM-A Mayos 2009 gambiae 3R\n",
      "Writing .batch.txt file for LDNe...\n",
      "\n",
      "Producing LDNe input for GadoBadzere, 2009, gambiae, 3R. 73 individuals, (gambcolu filter)\n",
      "GenotypeArray shape before pruning - (472212, 73, 2)\n",
      "iteration 1 retaining 215228 removing 256984 variants\n",
      "Converting to .dat AG1000G-CM-A GadoBadzere 2009 gambiae 3R\n",
      "Writing .batch.txt file for LDNe...\n",
      "\n",
      "Producing LDNe input for ZembeBorongo, 2009, gambiae, 3R. 24 individuals, (gambcolu filter)\n",
      "GenotypeArray shape before pruning - (523589, 24, 2)\n",
      "iteration 1 retaining 65239 removing 458350 variants\n",
      "Converting to .dat AG1000G-CM-A ZembeBorongo 2009 gambiae 3R\n",
      "Writing .batch.txt file for LDNe...\n",
      "\n",
      "Producing LDNe input for Daiguene, 2009, gambiae, 3R. 96 individuals, (gambcolu filter)\n",
      "GenotypeArray shape before pruning - (473181, 96, 2)\n",
      "iteration 1 retaining 233686 removing 239495 variants\n",
      "Converting to .dat AG1000G-CM-A Daiguene 2009 gambiae 3R\n",
      "Writing .batch.txt file for LDNe...\n",
      "\n",
      "Producing LDNe input for Manda, 2013, gambiae, 3R. 11 individuals, (gambcolu filter)\n",
      "GenotypeArray shape before pruning - (474090, 11, 2)\n",
      "iteration 1 retaining 36044 removing 438046 variants\n",
      "Converting to .dat AG1000G-CM-C Manda 2013 gambiae 3R\n",
      "Writing .batch.txt file for LDNe...\n",
      "\n",
      "Producing LDNe input for Libreville, 2000, gambiae, 3R. 69 individuals, (gambcolu filter)\n",
      "GenotypeArray shape before pruning - (598523, 69, 2)\n",
      "iteration 1 retaining 40378 removing 558145 variants\n",
      "Converting to .dat AG1000G-GA-A Libreville 2000 gambiae 3R\n",
      "Writing .batch.txt file for LDNe...\n",
      "\n",
      "Producing LDNe input for TwifoPraso, 2012, coluzzii, 3R. 25 individuals, (gambcolu filter)\n",
      "GenotypeArray shape before pruning - (557475, 25, 2)\n",
      "iteration 1 retaining 61898 removing 495577 variants\n",
      "Converting to .dat AG1000G-GH TwifoPraso 2012 coluzzii 3R\n",
      "Writing .batch.txt file for LDNe...\n",
      "\n",
      "Producing LDNe input for Takoradi, 2012, coluzzii, 3R. 24 individuals, (gambcolu filter)\n",
      "GenotypeArray shape before pruning - (545746, 24, 2)\n",
      "iteration 1 retaining 55491 removing 490255 variants\n",
      "Converting to .dat AG1000G-GH Takoradi 2012 coluzzii 3R\n",
      "Writing .batch.txt file for LDNe...\n",
      "\n",
      "Producing LDNe input for Madina, 2012, gambiae, 3R. 13 individuals, (gambcolu filter)\n",
      "GenotypeArray shape before pruning - (544762, 13, 2)\n",
      "iteration 1 retaining 42398 removing 502364 variants\n",
      "Converting to .dat AG1000G-GH Madina 2012 gambiae 3R\n",
      "Writing .batch.txt file for LDNe...\n",
      "\n",
      "Producing LDNe input for Madina, 2012, coluzzii, 3R. 14 individuals, (gambcolu filter)\n",
      "GenotypeArray shape before pruning - (565622, 14, 2)\n",
      "iteration 1 retaining 39707 removing 525915 variants\n",
      "Converting to .dat AG1000G-GH Madina 2012 coluzzii 3R\n",
      "Writing .batch.txt file for LDNe...\n",
      "\n",
      "Producing LDNe input for Koforidua, 2012, gambiae, 3R. 23 individuals, (gambcolu filter)\n",
      "GenotypeArray shape before pruning - (541203, 23, 2)\n",
      "iteration 1 retaining 48623 removing 492580 variants\n",
      "Converting to .dat AG1000G-GH Koforidua 2012 gambiae 3R\n",
      "Writing .batch.txt file for LDNe...\n",
      "\n",
      "Producing LDNe input for Njabakunda, 2011, intermediate, 3R. 11 individuals, (gambcolu filter)\n",
      "GenotypeArray shape before pruning - (513662, 11, 2)\n",
      "iteration 1 retaining 31016 removing 482646 variants\n",
      "Converting to .dat AG1000G-GM-A Njabakunda 2011 intermediate 3R\n",
      "Writing .batch.txt file for LDNe...\n",
      "\n",
      "Producing LDNe input for Njabakunda, 2011, gambiae, 3R. 58 individuals, (gambcolu filter)\n",
      "GenotypeArray shape before pruning - (603863, 58, 2)\n",
      "iteration 1 retaining 114029 removing 489834 variants\n",
      "Converting to .dat AG1000G-GM-A Njabakunda 2011 gambiae 3R\n",
      "Writing .batch.txt file for LDNe...\n",
      "\n",
      "Producing LDNe input for Tankular, 2012, coluzzii, 3R. 14 individuals, (gambcolu filter)\n",
      "GenotypeArray shape before pruning - (567446, 14, 2)\n",
      "iteration 1 retaining 57273 removing 510173 variants\n",
      "Converting to .dat AG1000G-GM-B Tankular 2012 coluzzii 3R\n",
      "Writing .batch.txt file for LDNe...\n",
      "\n",
      "Producing LDNe input for SareSambaSowe, 2012, gambiae, 3R. 9 individuals, (gambcolu filter)\n",
      "GenotypeArray shape before pruning - (940590, 9, 2)\n",
      "iteration 1 retaining 27404 removing 913186 variants\n",
      "Converting to .dat AG1000G-GM-B SareSambaSowe 2012 gambiae 3R\n",
      "Writing .batch.txt file for LDNe...\n",
      "\n",
      "Producing LDNe input for WaliKunda, 2012, coluzzii, 3R. 148 individuals, (gambcolu filter)\n",
      "GenotypeArray shape before pruning - (484979, 148, 2)\n",
      "iteration 1 retaining 254420 removing 230559 variants\n",
      "Converting to .dat AG1000G-GM-C WaliKunda 2012 coluzzii 3R\n",
      "Writing .batch.txt file for LDNe...\n",
      "\n",
      "Producing LDNe input for WaliKunda, 2012, intermediate, 3R. 24 individuals, (gambcolu filter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GenotypeArray shape before pruning - (542944, 24, 2)\n",
      "iteration 1 retaining 67275 removing 475669 variants\n",
      "Converting to .dat AG1000G-GM-C WaliKunda 2012 intermediate 3R\n",
      "Writing .batch.txt file for LDNe...\n",
      "\n",
      "Producing LDNe input for Koundara, 2012, gambiae, 3R. 18 individuals, (gambcolu filter)\n",
      "GenotypeArray shape before pruning - (650466, 18, 2)\n",
      "iteration 1 retaining 88398 removing 562068 variants\n",
      "Converting to .dat AG1000G-GN-A Koundara 2012 gambiae 3R\n",
      "Writing .batch.txt file for LDNe...\n",
      "\n",
      "Producing LDNe input for Koraboh, 2012, gambiae, 3R. 22 individuals, (gambcolu filter)\n",
      "GenotypeArray shape before pruning - (502328, 22, 2)\n",
      "iteration 1 retaining 51397 removing 450931 variants\n",
      "Converting to .dat AG1000G-GN-A Koraboh 2012 gambiae 3R\n",
      "Writing .batch.txt file for LDNe...\n",
      "\n",
      "Producing LDNe input for Koraboh, 2012, gambiae, 3R. 38 individuals, (gambcolu filter)\n",
      "GenotypeArray shape before pruning - (565942, 38, 2)\n",
      "iteration 1 retaining 112962 removing 452980 variants\n",
      "Converting to .dat AG1000G-GN-B Koraboh 2012 gambiae 3R\n",
      "Writing .batch.txt file for LDNe...\n",
      "\n",
      "Producing LDNe input for Koundara, 2012, gambiae, 3R. 45 individuals, (gambcolu filter)\n",
      "GenotypeArray shape before pruning - (520796, 45, 2)\n",
      "iteration 1 retaining 123540 removing 397256 variants\n",
      "Converting to .dat AG1000G-GN-B Koundara 2012 gambiae 3R\n",
      "Writing .batch.txt file for LDNe...\n",
      "\n",
      "Producing LDNe input for ToumaniOulena, 2012, gambiae, 3R. 60 individuals, (gambcolu filter)\n",
      "GenotypeArray shape before pruning - (499291, 60, 2)\n",
      "iteration 1 retaining 115299 removing 383992 variants\n",
      "Converting to .dat AG1000G-GN-B ToumaniOulena 2012 gambiae 3R\n",
      "Writing .batch.txt file for LDNe...\n",
      "\n",
      "Producing LDNe input for Takan, 2012, coluzzii, 3R. 26 individuals, (gambcolu filter)\n",
      "GenotypeArray shape before pruning - (544290, 26, 2)\n",
      "iteration 1 retaining 66770 removing 477520 variants\n",
      "Converting to .dat AG1000G-GN-B Takan 2012 coluzzii 3R\n",
      "Writing .batch.txt file for LDNe...\n",
      "\n",
      "Producing LDNe input for Bioko, 2002, gambiae, 3R. 10 individuals, (gambcolu filter)\n",
      "GenotypeArray shape before pruning - (472713, 10, 2)\n",
      "iteration 1 retaining 19375 removing 453338 variants\n",
      "Converting to .dat AG1000G-GQ Bioko 2002 gambiae 3R\n",
      "Writing .batch.txt file for LDNe...\n",
      "\n",
      "Producing LDNe input for Antula, 2010, gambiae, 3R. 15 individuals, (gambcolu filter)\n",
      "GenotypeArray shape before pruning - (611566, 15, 2)\n",
      "iteration 1 retaining 63194 removing 548372 variants\n",
      "Converting to .dat AG1000G-GW Antula 2010 gambiae 3R\n",
      "Writing .batch.txt file for LDNe...\n",
      "\n",
      "Producing LDNe input for Antula, 2010, intermediate, 3R. 45 individuals, (gambcolu filter)\n",
      "GenotypeArray shape before pruning - (547143, 45, 2)\n",
      "iteration 1 retaining 144896 removing 402247 variants\n",
      "Converting to .dat AG1000G-GW Antula 2010 intermediate 3R\n",
      "Writing .batch.txt file for LDNe...\n",
      "\n",
      "Producing LDNe input for Safim, 2010, intermediate, 3R. 27 individuals, (gambcolu filter)\n",
      "GenotypeArray shape before pruning - (606568, 27, 2)\n",
      "iteration 1 retaining 82730 removing 523838 variants\n",
      "Converting to .dat AG1000G-GW Safim 2010 intermediate 3R\n",
      "Writing .batch.txt file for LDNe...\n",
      "\n",
      "Producing LDNe input for Kilifi, 2012, arabiensis, 3R. 10 individuals, (arabiensis filter)\n",
      "GenotypeArray shape before pruning - (271348, 10, 2)\n",
      "iteration 1 retaining 16419 removing 254929 variants\n",
      "Converting to .dat AG1000G-KE Kilifi 2012 arabiensis 3R\n",
      "Writing .batch.txt file for LDNe...\n",
      "\n",
      "Producing LDNe input for Kilifi, 2012, intermediate, 3R. 45 individuals, (gambcolu filter)\n",
      "GenotypeArray shape before pruning - (341822, 45, 2)\n",
      "iteration 1 retaining 4707 removing 337115 variants\n",
      "Converting to .dat AG1000G-KE Kilifi 2012 intermediate 3R\n",
      "Writing .batch.txt file for LDNe...\n",
      "\n",
      "Producing LDNe input for Kilifi, 2012, gambiae, 3R. 9 individuals, (gambcolu filter)\n",
      "GenotypeArray shape before pruning - (346181, 9, 2)\n",
      "iteration 1 retaining 5738 removing 340443 variants\n",
      "Converting to .dat AG1000G-KE Kilifi 2012 gambiae 3R\n",
      "Writing .batch.txt file for LDNe...\n",
      "\n",
      "Producing LDNe input for Kilifi, 2000, gambiae, 3R. 19 individuals, (gambcolu filter)\n",
      "GenotypeArray shape before pruning - (609857, 19, 2)\n",
      "iteration 1 retaining 33909 removing 575948 variants\n",
      "Converting to .dat AG1000G-KE Kilifi 2000 gambiae 3R\n",
      "Writing .batch.txt file for LDNe...\n",
      "\n",
      "Producing LDNe input for Kababougou, 2014, coluzzii, 3R. 12 individuals, (gambcolu filter)\n",
      "GenotypeArray shape before pruning - (479318, 12, 2)\n",
      "iteration 1 retaining 43629 removing 435689 variants\n",
      "Converting to .dat AG1000G-ML-A Kababougou 2014 coluzzii 3R\n",
      "Writing .batch.txt file for LDNe...\n",
      "\n",
      "Producing LDNe input for Kababougou, 2014, gambiae, 3R. 28 individuals, (gambcolu filter)\n",
      "GenotypeArray shape before pruning - (582618, 28, 2)\n",
      "iteration 1 retaining 90233 removing 492385 variants\n",
      "Converting to .dat AG1000G-ML-A Kababougou 2014 gambiae 3R\n",
      "Writing .batch.txt file for LDNe...\n",
      "\n",
      "Producing LDNe input for Ouassorola, 2014, coluzzii, 3R. 9 individuals, (gambcolu filter)\n",
      "GenotypeArray shape before pruning - (921132, 9, 2)\n",
      "iteration 1 retaining 28010 removing 893122 variants\n",
      "Converting to .dat AG1000G-ML-A Ouassorola 2014 coluzzii 3R\n",
      "Writing .batch.txt file for LDNe...\n",
      "\n",
      "Producing LDNe input for Bancoumana, 2004, gambiae, 3R. 9 individuals, (gambcolu filter)\n",
      "GenotypeArray shape before pruning - (959009, 9, 2)\n",
      "iteration 1 retaining 29206 removing 929803 variants\n",
      "Converting to .dat AG1000G-ML-B Bancoumana 2004 gambiae 3R\n",
      "Writing .batch.txt file for LDNe...\n",
      "\n",
      "Producing LDNe input for Kela, 2004, gambiae, 3R. 23 individuals, (gambcolu filter)\n",
      "GenotypeArray shape before pruning - (526159, 23, 2)\n",
      "iteration 1 retaining 55491 removing 470668 variants\n",
      "Converting to .dat AG1000G-ML-B Kela 2004 gambiae 3R\n",
      "Writing .batch.txt file for LDNe...\n",
      "\n",
      "Producing LDNe input for Douna, 2004, coluzzii, 3R. 19 individuals, (gambcolu filter)\n",
      "GenotypeArray shape before pruning - (641822, 19, 2)\n",
      "iteration 1 retaining 90009 removing 551813 variants\n",
      "Converting to .dat AG1000G-ML-B Douna 2004 coluzzii 3R\n",
      "Writing .batch.txt file for LDNe...\n",
      "\n",
      "Producing LDNe input for Chikhwawa, 2015, arabiensis, 3R. 41 individuals, (arabiensis filter)\n",
      "GenotypeArray shape before pruning - (309225, 41, 2)\n",
      "iteration 1 retaining 51077 removing 258148 variants\n",
      "Converting to .dat AG1000G-MW Chikhwawa 2015 arabiensis 3R\n",
      "Writing .batch.txt file for LDNe...\n",
      "\n",
      "Producing LDNe input for Furvela, 2004, gambiae, 3R. 71 individuals, (gambcolu filter)\n",
      "GenotypeArray shape before pruning - (520982, 71, 2)\n",
      "iteration 1 retaining 35029 removing 485953 variants\n",
      "Converting to .dat AG1000G-MZ Furvela 2004 gambiae 3R\n",
      "Writing .batch.txt file for LDNe...\n",
      "\n",
      "Producing LDNe input for Muleba, 2015, arabiensis, 3R. 137 individuals, (arabiensis filter)\n",
      "GenotypeArray shape before pruning - (373744, 137, 2)\n",
      "iteration 1 retaining 87742 removing 286002 variants\n",
      "Converting to .dat AG1000G-TZ Muleba 2015 arabiensis 3R\n",
      "Writing .batch.txt file for LDNe...\n",
      "\n",
      "Producing LDNe input for Muleba, 2015, gambiae, 3R. 32 individuals, (gambcolu filter)\n",
      "GenotypeArray shape before pruning - (520821, 32, 2)\n",
      "iteration 1 retaining 85901 removing 434920 variants\n",
      "Converting to .dat AG1000G-TZ Muleba 2015 gambiae 3R\n",
      "Writing .batch.txt file for LDNe...\n",
      "\n",
      "Producing LDNe input for Moshi, 2012, arabiensis, 3R. 40 individuals, (arabiensis filter)\n",
      "GenotypeArray shape before pruning - (324088, 40, 2)\n",
      "iteration 1 retaining 47179 removing 276909 variants\n",
      "Converting to .dat AG1000G-TZ Moshi 2012 arabiensis 3R\n",
      "Writing .batch.txt file for LDNe...\n",
      "\n",
      "Producing LDNe input for Tarime, 2012, arabiensis, 3R. 47 individuals, (arabiensis filter)\n",
      "GenotypeArray shape before pruning - (376665, 47, 2)\n",
      "iteration 1 retaining 61560 removing 315105 variants\n",
      "Converting to .dat AG1000G-TZ Tarime 2012 arabiensis 3R\n",
      "Writing .batch.txt file for LDNe...\n",
      "\n",
      "Producing LDNe input for Muheza, 2013, gambiae, 3R. 36 individuals, (gambcolu filter)\n",
      "GenotypeArray shape before pruning - (565838, 36, 2)\n",
      "iteration 1 retaining 40995 removing 524843 variants\n",
      "Converting to .dat AG1000G-TZ Muheza 2013 gambiae 3R\n",
      "Writing .batch.txt file for LDNe...\n",
      "\n",
      "Producing LDNe input for Nagongera, 2012, arabiensis, 3R. 81 individuals, (arabiensis filter)\n",
      "GenotypeArray shape before pruning - (336877, 81, 2)\n",
      "iteration 1 retaining 76457 removing 260420 variants\n",
      "Converting to .dat AG1000G-UG Nagongera 2012 arabiensis 3R\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing .batch.txt file for LDNe...\n",
      "\n",
      "Producing LDNe input for Nagongera, 2012, gambiae, 3R. 112 individuals, (gambcolu filter)\n",
      "GenotypeArray shape before pruning - (479696, 112, 2)\n",
      "iteration 1 retaining 213994 removing 265702 variants\n",
      "Converting to .dat AG1000G-UG Nagongera 2012 gambiae 3R\n",
      "Writing .batch.txt file for LDNe...\n",
      "\n",
      "Producing LDNe input for Kihihi, 2012, gambiae, 3R. 95 individuals, (gambcolu filter)\n",
      "GenotypeArray shape before pruning - (510241, 95, 2)\n",
      "iteration 1 retaining 198070 removing 312171 variants\n",
      "Converting to .dat AG1000G-UG Kihihi 2012 gambiae 3R\n",
      "Writing .batch.txt file for LDNe...\n"
     ]
    }
   ],
   "source": [
    "for chrom in chroms:\n",
    "\n",
    "    print(f\"------------------------ LDNe_Ag -------------------------------\\n\")\n",
    "    print(f\"Storing metadata in data/Phase3.LDNe.tsv\")\n",
    "    #with open('../data/Phase3.LDNe.tsv', 'w') as metafile:\n",
    "    #    metafile.write(\"sample_set\\tlocation\\tyear\\tspecies\\tchromosome\\n\")\n",
    " \n",
    "        \n",
    "    #filter the gff3 to be coding and regulatory regions\n",
    "    df = allel.gff3_to_dataframe(f\"{argsgff}\")\n",
    "    coding_reg_df = df[~df.type.isin(['chromosome', 'three_prime_UTR','five_prime_UTR',\n",
    "                    'mRNA', 'CDS', 'exon'])].drop(columns=['source', 'strand', 'phase', 'score'])\n",
    "    coding_reg_df = coding_reg_df[coding_reg_df.seqid == chrom]\n",
    "\n",
    "    for _set in all_sets:\n",
    "    \n",
    "        #subset metadata\n",
    "        metadata = manifest[manifest.sample_set == _set].reset_index(drop=True)\n",
    "\n",
    "        ### loop through combos \n",
    "        for loc in metadata.location.unique():\n",
    "\n",
    "            nmeta = metadata[metadata.location == loc]\n",
    "\n",
    "            for yr in nmeta.year.unique():\n",
    "\n",
    "                nmeta2 = nmeta[nmeta.year == yr]\n",
    "                \n",
    "                #have edited .species_gambiae_coluzzii column to contain arabiensis instead of NA \n",
    "                for sp in nmeta2.species_gambiae_coluzzii.unique():\n",
    "                    \n",
    "                    # if file exists ignore and skip\n",
    "                    myfile = Path(f\"../data/dat/{_set}.{loc}.{yr}.{sp}.{chrom}.dat\")\n",
    "                    if myfile.is_file():\n",
    "                        continue\n",
    "\n",
    "                    #if there is less than 9 samples than skip\n",
    "                    if (nmeta2.species_gambiae_coluzzii == sp).sum() <= 8:\n",
    "                        continue\n",
    "                    \n",
    "                    #need to implement separate site filters for arabiensis v gamb_colu \n",
    "                    if sp == 'arabiensis':  \n",
    "                        geno, positions = load_arrays_noncoding_and_centromeres(local_path,_set, chrom, coding_reg_df, sitefilter='arab')\n",
    "                        #filter to species \n",
    "                        nmeta3 = nmeta2[nmeta2.species_gambiae_coluzzii == sp]\n",
    "                        flt = np.array(nmeta3.index)\n",
    "                        #filter to correct loc, year, species individuals\n",
    "                        gn = geno.take(flt, axis=1)\n",
    "                        \n",
    "                        print(f\"\\nProducing LDNe input for {loc}, {yr}, {sp}, {chrom}. {nmeta3.shape[0]} individuals, (arabiensis filter)\")\n",
    "                        convert2dat(gn, positions, n, _set, loc, yr, sp, chrom)\n",
    "                \n",
    "                    else:\n",
    "                        geno, positions = load_arrays_noncoding_and_centromeres(local_path, _set, chrom, coding_reg_df, sitefilter='gamb_colu')\n",
    "                        #filter to species \n",
    "                        nmeta3 = nmeta2[nmeta2.species_gambiae_coluzzii == sp]\n",
    "                        flt = np.array(nmeta3.index)\n",
    "                        #filter to correct loc, year, species individuals\n",
    "                        gn = geno.take(flt, axis=1)   \n",
    "                        \n",
    "                        print(f\"\\nProducing LDNe input for {loc}, {yr}, {sp}, {chrom}. {nmeta3.shape[0]} individuals, (gambcolu filter)\")\n",
    "                        convert2dat(gn, positions, n, _set, loc, yr, sp, chrom)\n",
    "                        \n",
    "                    #write metadata file for samples that are included\n",
    "                    with open('../data/Phase3.LDNe.tsv', 'a') as metafile:\n",
    "                        metafile.write(f'{_set}\\t{loc}\\t{yr}\\t{sp}\\t{chrom}\\n')\n",
    "                    \n",
    "                    #write batch file for LDNe \n",
    "                    print(\"Writing .batch.txt file for LDNe...\")\n",
    "                    with open(f'../analysis/LDNe/batch/{_set}.{loc}.{yr}.{sp}.{chrom}.batch.txt', 'w') as batch_file:\n",
    "                        batch_file.write(f'1\\t0\\n1\\n0.05\\t-1\\n15\\t0\\t1\\n1\\n0\\n0\\n0\\n0\\nanalysis/LDNe/Ag_LDNe_{_set}.{loc}.{yr}.{sp}.{chrom}.out\\n')\n",
    "                        batch_file.write(f\"data/dat/{_set}.{loc}.{yr}.{sp}.{chrom}.dat\\n\")\n",
    "                        batch_file.write(\"*\")\n",
    "                        batch_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zarr to Temporal\n",
    "\n",
    "I want to test the Temporal estimator, using the Burkina Faso samples which are replicated in 2012 and 2014. For NeEstimator, we need to write out a similar file as above, however, with the two populations concatenated on top of each other. Ill redefine a new function and then run that. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "chroms = ['2L', '2R', '3L', '3R', 'X']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Burkina_manifest = manifest[manifest.country == 'Burkina Faso']\n",
    "Burkina_manifest = Burkina_manifest[Burkina_manifest.year != 2004]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets see which sample set contains which years..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>year</th>\n",
       "      <th>2012</th>\n",
       "      <th>2014</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sample_set</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AG1000G-BF-A</th>\n",
       "      <td>181</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AG1000G-BF-B</th>\n",
       "      <td>0</td>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "year          2012  2014\n",
       "sample_set              \n",
       "AG1000G-BF-A   181     0\n",
       "AG1000G-BF-B     0   102"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sets = pd.crosstab(Burkina_manifest.sample_set, Burkina_manifest.year)\n",
    "sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And which locations have both years?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>year</th>\n",
       "      <th>2012</th>\n",
       "      <th>2014</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>location</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Bana</th>\n",
       "      <td>65</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pala</th>\n",
       "      <td>59</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Souroukoudinga</th>\n",
       "      <td>57</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "year            2012  2014\n",
       "location                  \n",
       "Bana              65    63\n",
       "Pala              59    18\n",
       "Souroukoudinga    57    21"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temporal_samples = pd.crosstab(Burkina_manifest.location, Burkina_manifest.year)\n",
    "temporal_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nice, so we have three locations in Burkina that have been replicated. We can use these for temporal analysis of effective population size. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----  converting zarr to dat for Bana 2012 2014 2L ------\n",
      "GenotypeArray shape before pruning - (737620, 65, 2)\n",
      "iteration 1 retaining 318144 removing 419476 variants\n",
      "iteration 1 retaining 308970 removing 412122 variants\n",
      "Array one is of size (10000, 65, 2) and array two is size (10000, 63, 2)\n",
      "Converting to .dat Bana 2L years 2012 2014\n",
      "-----  converting zarr to dat for Pala 2012 2014 2L ------\n",
      "GenotypeArray shape before pruning - (805111, 59, 2)\n",
      "iteration 1 retaining 295408 removing 509703 variants\n",
      "iteration 1 retaining 127167 removing 811791 variants\n",
      "Array one is of size (10000, 59, 2) and array two is size (10000, 18, 2)\n",
      "Converting to .dat Pala 2L years 2012 2014\n",
      "-----  converting zarr to dat for Souroukoudinga 2012 2014 2L ------\n",
      "GenotypeArray shape before pruning - (777066, 57, 2)\n",
      "iteration 1 retaining 294329 removing 482737 variants\n",
      "iteration 1 retaining 97490 removing 611763 variants\n",
      "Array one is of size (10000, 57, 2) and array two is size (10000, 21, 2)\n",
      "Converting to .dat Souroukoudinga 2L years 2012 2014\n",
      "-----  converting zarr to dat for Bana 2012 2014 2R ------\n",
      "GenotypeArray shape before pruning - (838001, 65, 2)\n",
      "iteration 1 retaining 247812 removing 590189 variants\n",
      "iteration 1 retaining 244402 removing 558803 variants\n",
      "Array one is of size (10000, 65, 2) and array two is size (10000, 63, 2)\n",
      "Converting to .dat Bana 2R years 2012 2014\n",
      "-----  converting zarr to dat for Pala 2012 2014 2R ------\n",
      "GenotypeArray shape before pruning - (919030, 59, 2)\n",
      "iteration 1 retaining 280299 removing 638731 variants\n",
      "iteration 1 retaining 135297 removing 894479 variants\n",
      "Array one is of size (10000, 59, 2) and array two is size (10000, 18, 2)\n",
      "Converting to .dat Pala 2R years 2012 2014\n",
      "-----  converting zarr to dat for Souroukoudinga 2012 2014 2R ------\n",
      "GenotypeArray shape before pruning - (888218, 57, 2)\n",
      "iteration 1 retaining 240888 removing 647330 variants\n",
      "iteration 1 retaining 82073 removing 721601 variants\n",
      "Array one is of size (10000, 57, 2) and array two is size (10000, 21, 2)\n",
      "Converting to .dat Souroukoudinga 2R years 2012 2014\n",
      "-----  converting zarr to dat for Bana 2012 2014 3L ------\n",
      "GenotypeArray shape before pruning - (534702, 65, 2)\n",
      "iteration 1 retaining 267249 removing 267453 variants\n",
      "iteration 1 retaining 257173 removing 266389 variants\n",
      "Array one is of size (10000, 65, 2) and array two is size (10000, 63, 2)\n",
      "Converting to .dat Bana 3L years 2012 2014\n",
      "-----  converting zarr to dat for Pala 2012 2014 3L ------\n",
      "GenotypeArray shape before pruning - (565965, 59, 2)\n",
      "iteration 1 retaining 259751 removing 306214 variants\n",
      "iteration 1 retaining 88361 removing 562805 variants\n",
      "Array one is of size (10000, 59, 2) and array two is size (10000, 18, 2)\n",
      "Converting to .dat Pala 3L years 2012 2014\n",
      "-----  converting zarr to dat for Souroukoudinga 2012 2014 3L ------\n",
      "GenotypeArray shape before pruning - (554724, 57, 2)\n",
      "iteration 1 retaining 251128 removing 303596 variants\n",
      "iteration 1 retaining 60228 removing 438540 variants\n",
      "Array one is of size (10000, 57, 2) and array two is size (10000, 21, 2)\n",
      "Converting to .dat Souroukoudinga 3L years 2012 2014\n",
      "-----  converting zarr to dat for Bana 2012 2014 3R ------\n",
      "GenotypeArray shape before pruning - (698405, 65, 2)\n",
      "iteration 1 retaining 299804 removing 398601 variants\n",
      "iteration 1 retaining 293500 removing 383714 variants\n",
      "Array one is of size (10000, 65, 2) and array two is size (10000, 63, 2)\n",
      "Converting to .dat Bana 3R years 2012 2014\n",
      "-----  converting zarr to dat for Pala 2012 2014 3R ------\n",
      "GenotypeArray shape before pruning - (765113, 59, 2)\n",
      "iteration 1 retaining 279462 removing 485651 variants\n",
      "iteration 1 retaining 109578 removing 789781 variants\n",
      "Array one is of size (10000, 59, 2) and array two is size (10000, 18, 2)\n",
      "Converting to .dat Pala 3R years 2012 2014\n",
      "-----  converting zarr to dat for Souroukoudinga 2012 2014 3R ------\n",
      "GenotypeArray shape before pruning - (734721, 57, 2)\n",
      "iteration 1 retaining 279753 removing 454968 variants\n",
      "iteration 1 retaining 73617 removing 590673 variants\n",
      "Array one is of size (10000, 57, 2) and array two is size (10000, 21, 2)\n",
      "Converting to .dat Souroukoudinga 3R years 2012 2014\n",
      "-----  converting zarr to dat for Bana 2012 2014 X ------\n",
      "GenotypeArray shape before pruning - (116321, 65, 2)\n",
      "iteration 1 retaining 45192 removing 71129 variants\n",
      "iteration 1 retaining 42444 removing 71073 variants\n",
      "Array one is of size (10000, 65, 2) and array two is size (10000, 63, 2)\n",
      "Converting to .dat Bana X years 2012 2014\n",
      "-----  converting zarr to dat for Pala 2012 2014 X ------\n",
      "GenotypeArray shape before pruning - (121049, 59, 2)\n",
      "iteration 1 retaining 45020 removing 76029 variants\n",
      "iteration 1 retaining 22622 removing 145019 variants\n",
      "Array one is of size (5347, 59, 2) and array two is size (5347, 18, 2)\n",
      "Converting to .dat Pala X years 2012 2014\n",
      "-----  converting zarr to dat for Souroukoudinga 2012 2014 X ------\n",
      "GenotypeArray shape before pruning - (118445, 57, 2)\n",
      "iteration 1 retaining 51112 removing 67333 variants\n",
      "iteration 1 retaining 12778 removing 95095 variants\n",
      "Array one is of size (5746, 57, 2) and array two is size (5746, 21, 2)\n",
      "Converting to .dat Souroukoudinga X years 2012 2014\n"
     ]
    }
   ],
   "source": [
    "set2012, set2014 = sets.index\n",
    "\n",
    "df = allel.gff3_to_dataframe(f\"{argsgff}\")\n",
    "coding_reg_df = df[~df.type.isin(['chromosome', 'three_prime_UTR','five_prime_UTR',\n",
    "                'mRNA', 'CDS', 'exon'])].drop(columns=['source', 'strand', 'phase', 'score'])\n",
    "coding_reg_df = coding_reg_df[coding_reg_df.seqid == chrom]\n",
    "\n",
    "metadata12 = manifest[manifest.sample_set == set2012].reset_index(drop=True)\n",
    "metadata14 = manifest[manifest.sample_set == set2014].reset_index(drop=True)\n",
    "\n",
    "for chrom in chroms:\n",
    "    for location in temporal_samples.index:\n",
    "        \n",
    "        myfile = Path(f\"../data/dat/temporal.{location}.2012.2014.{chrom}.dat\")\n",
    "        if myfile.is_file():\n",
    "            continue\n",
    "        \n",
    "        gn12, pos12 = load_arrays_noncoding_and_centromeres(local_path,set2012, \n",
    "                                                       chrom, \n",
    "                                                       coding_reg_df, \n",
    "                                                       sitefilter='gamb_colu', \n",
    "                                                       filter_centro=False)\n",
    "        meta12 = metadata12[metadata12.location == location]\n",
    "        gn12 = gn12.take(np.array(meta12.index), axis=1)\n",
    "        \n",
    "        gn14, pos14 = load_arrays_noncoding_and_centromeres(local_path,set2014, \n",
    "                                                       chrom, \n",
    "                                                       coding_reg_df, \n",
    "                                                       sitefilter='gamb_colu', \n",
    "                                                       filter_centro=False)\n",
    "        meta14 = metadata14[metadata14.location == location]\n",
    "        gn14 = gn14.take(np.array(meta14.index), axis=1)\n",
    "        \n",
    "        convert2dattemporal(gn12, gn14, pos12, pos14, 10000, location, 2012, 2014, chrom)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "for chrom in chroms:\n",
    "    for loc in temporal_samples.index:\n",
    "        \n",
    "        with open(f'../analysis/LDNe/batch/{loc}.{chrom}.batch.txt', 'w') as batch_file:\n",
    "            batch_file.write(f'8\\t0\\n1\\n0.05\\t-1\\n0\\t0\\t24\\n15\\t0\\t1\\n1\\n0\\n0\\n0\\nanalysis/LDNe/temporal.{loc}.{chrom}.out\\n')\n",
    "            batch_file.write(f\"data/dat/temporal.{loc}.2012.2014.{chrom}.dat\\n\")\n",
    "            batch_file.write(\"*\")\n",
    "            batch_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

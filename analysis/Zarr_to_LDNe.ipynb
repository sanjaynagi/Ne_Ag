{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import zarr\n",
    "import allel\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zarr2LDNe\n",
    " \n",
    "       Sanjay C Nagi      06/07/20\n",
    "\n",
    "I have written a snakemake pipeline which subsets and downsamples the zarr genotype arrays in phase 2, and runs LDNe on the populations within. I now want to run this on all of phase 3. As phase 3 is grouped by sample_set, I want to run LDNe on all locations + years that have greater than 15 samples, though this number is currently arbitrary.\n",
    "\n",
    "Which groups of samples do we want to run LDNe on? see below...\n",
    "### Phase 3 samples for LDNe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "manifest = pd.read_csv(\"../../data/phase3/Ag1000g.phase3.manifest.tsv\", sep=\"\\t\")\n",
    "#manifest[manifest.n_samples >= 15]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The idea here would be to (in snakemake) loop through each sample_set (not shown above), then within each sample set loop through each location and finally year, where there is temporal samples. \n",
    "\n",
    "At each point we need to extract the appropriate genotypes from the sample set zarrs. We'll also need to filter SNPs, and then can run the downstream LDNe prep."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "manifest = pd.read_csv(\"../../data/phase3/Ag1000g.phase3.manifest.full.tsv\", sep=\"\\t\")\n",
    "manifest.location = [loc.replace(\" \", \"\") for loc in manifest.location]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Phase 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_sets = manifest.sample_set.unique()\n",
    "\n",
    "chroms = ['3L','3R']\n",
    "n = 20000\n",
    "argsgff = \"../data/An.gambiae-PEST-BASEFEATURES_agamP4.12.gff3.gz\"\n",
    "\n",
    "local_path = Path(\"/home/sanj/ag1000g/data/phase3/\").expanduser() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As phase 3 is organised into sample sets, I will loop through each sample set, and each location within that, each year within that, each species, producing FSTAT format files for LDNe, and writing out metadata along the way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### functions #####\n",
    "\n",
    "def ld_prune(gn, size, step, threshold=.2, n_iter=1, blen=10000):\n",
    "    \n",
    "    gn_alt = gn.to_n_alt()\n",
    "\n",
    "    for i in range(n_iter):\n",
    "        loc_unlinked = allel.locate_unlinked(gn_alt, size=size, step=step, threshold=threshold, blen=blen)\n",
    "        n = np.count_nonzero(loc_unlinked)\n",
    "        n_remove = gn.shape[0] - n\n",
    "        print('iteration', i+1, 'retaining', n, 'removing', n_remove, 'variants')\n",
    "        gn = gn.compress(loc_unlinked, axis=0)\n",
    "    return(gn, loc_unlinked)\n",
    "    \n",
    "\n",
    "def replace_with_dict2_generic(ar, dic, assume_all_present=False):\n",
    "    # Extract out keys and values\n",
    "    k = np.array(list(dic.keys()))\n",
    "    v = np.array(list(dic.values()))\n",
    "\n",
    "    # Get argsort indices\n",
    "    sidx = k.argsort()\n",
    "\n",
    "    ks = k[sidx]\n",
    "    vs = v[sidx]\n",
    "    idx = np.searchsorted(ks,ar)\n",
    "\n",
    "    if assume_all_present==0:\n",
    "        idx[idx==len(vs)] = 0\n",
    "        mask = ks[idx] == ar\n",
    "        return np.where(mask, vs[idx], ar)\n",
    "    else:\n",
    "        return vs[idx]\n",
    "    \n",
    "def load_arrays_noncoding_and_centromeres(local_path, _set, chrom, coding_reg_df, sitefilter='gamb_colu'):\n",
    "    \n",
    "    \"\"\"\n",
    "    This function reads and filters a genotyping array to the noncoding, noncentromeric regions, and applys a filter depending on \n",
    "    whether the samples are arabiensis (arab) or gambiae/coluzzii (gamb_colu)\n",
    "    \"\"\"\n",
    "    Ag_array = zarr.open_array(f\"{local_path}/snp_genotypes/all/{_set}/{chrom}/calldata/GT/\", mode = 'r')\n",
    "    filters = zarr.open(f\"{local_path}/site_filters/dt_20200416/{sitefilter}/{chrom}/variants/filter_pass\", mode=\"r\")\n",
    "    positions = zarr.open_array(f\"{local_path}/snp_genotypes/all/sites/{chrom}/variants/POS/\", mode='r')\n",
    "    positions = positions[:][filters[:]]    \n",
    "    geno = allel.GenotypeDaskArray(Ag_array)\n",
    "    geno = geno[filters[:]]\n",
    "    \n",
    "    if chrom == '2L':\n",
    "        centromere = (positions > 3000000)\n",
    "    elif chrom == '2R':\n",
    "        centromere = (positions < 57000000)\n",
    "    elif chrom == '3L':\n",
    "        centromere = (positions > 2000000)\n",
    "    elif chrom == '3R':\n",
    "        centromere = (positions < 50000000)\n",
    "    elif chrom == 'X':\n",
    "        centromere = (positions < 21000000) \n",
    "        \n",
    "    positions = allel.SortedIndex(positions[centromere])\n",
    "    #get boolean array for positions that are coding - allel.locate_ranges so fast!\n",
    "    coding = positions.locate_ranges(coding_reg_df.start, coding_reg_df.end, strict=False)\n",
    "    #compress to get noncoding SNPs and remove centromeric regions of low recombination\n",
    "    #get non-centromeric regions. currently chosen by eye based on ag1000g phase1 paper fig1.\n",
    "  \n",
    "    geno = geno.compress(centromere, axis=0)\n",
    "    geno = geno.compress(~coding, axis=0) #we want noncoding regions so '~' to get inverse of boolean\n",
    "    positions = positions[~coding]\n",
    "    \n",
    "    return(geno, positions)\n",
    "\n",
    "def convert2dat(gn, positions, n, _set, loc, yr, sp, chrom):\n",
    "    \n",
    "    \"\"\"\n",
    "    This function takes a genotyping array and positions, along with info on the sample_set, location , year, species, chrom,\n",
    "    and converts the genotyping array into a .dat file, suitable for use with LDNe. It randomly downsamples the genotyping array\n",
    "    by n SNPs\n",
    "    \"\"\"\n",
    "\n",
    "    # Biallelic and MAF 0.05 filter\n",
    "    ac = gn.count_alleles()\n",
    "    bial_ = ac.is_biallelic()\n",
    "    gn = gn.compress(bial_, axis=0)\n",
    "    ac = gn.count_alleles()\n",
    "    \n",
    "    freqs = ac.to_frequencies().compute()\n",
    "    ALT1 = freqs[:,1] > 0.05\n",
    "    ALT2 = freqs[:,2] > 0.05\n",
    "    ALT3 = freqs[:,3] > 0.05\n",
    "    maf_flt = np.logical_or(ALT1, ALT2, ALT3)\n",
    "    gn = gn.compress(maf_flt, axis=0)\n",
    "    \n",
    "    ## LD pruning\n",
    "    print(f\"GenotypeArray shape before pruning - {gn.shape}\")\n",
    "    gnu, loc_unlinked = ld_prune(gn, size=500, step=250, threshold=.2, n_iter=1, blen=10000)\n",
    "\n",
    "    #take random sample of n SNPs\n",
    "    if gnu.shape[0] < n:\n",
    "        snp_sample = np.random.choice(gnu.shape[0], gnu.shape[0], replace=False)\n",
    "    else :\n",
    "        snp_sample = np.random.choice(gnu.shape[0], n, replace=False)\n",
    "    \n",
    "    snp_sample.sort()\n",
    "    gnr = np.array(gnu[snp_sample][:])\n",
    "    gnr = gnr.astype(str)\n",
    "    \n",
    "    pos = positions[bial_]\n",
    "    pos = pos[maf_flt]\n",
    "    pos = pos[loc_unlinked]\n",
    "    pos = pos[snp_sample]\n",
    "    prefix = f'{chrom}_'\n",
    "    pos_string = [prefix + p for p in pos.astype(str)]\n",
    "\n",
    "    gnr[gnr == '-1'] = '00' #convert missing alleles \n",
    "    dat = np.empty([gnr.shape[0], gnr.shape[1]])\n",
    "\n",
    "    #join genotypes in same individual \n",
    "    print(f\"Converting to .dat {_set} {loc} {yr} {sp} {chrom}\")\n",
    "    for x in range(gnr.shape[0]):\n",
    "        for y in range(gnr.shape[1]):\n",
    "            dat[x,y] = ''.join(gnr[x,y])\n",
    "\n",
    "    #convert to .dat format genotypes \n",
    "    dat = dat.astype(str)\n",
    "    dat_convert_dict = {'0.0':'0101',\n",
    "                        '1.0':'0102',\n",
    "                        '2.0':'0103',\n",
    "                        '3.0':'0104',\n",
    "                        '10.0':'0201',\n",
    "                        '11.0':'0202',\n",
    "                        '12.0':'0203',\n",
    "                        '13.0':'0204',\n",
    "                        '20.0':'0301',\n",
    "                        '21.0':'0302',\n",
    "                        '22.0':'0303',\n",
    "                        '23.0':'0304',\n",
    "                        '30.0':'0401',\n",
    "                        '31.0':'0402',\n",
    "                        '32.0':'0403',\n",
    "                        '33.0':'0404'}\n",
    "    ## convert values to FSTAT .dat format\n",
    "    dat = replace_with_dict2_generic(dat, dat_convert_dict, assume_all_present=False)\n",
    "    \n",
    "    #stack population name and transposed genotypes \n",
    "    popnames = np.repeat(f\"{_set}{loc}{yr}{sp}{chrom}\", gnr.shape[1])\n",
    "    dat = np.column_stack((popnames, dat.T)) #\n",
    "    \n",
    "    #write out .dat file for LDNe \n",
    "    with open(f'../data/dat/{_set}.{loc}.{yr}.{sp}.{chrom}.dat', 'w') as datfile:\n",
    "        datfile.write(f'{gnr.shape[1]}\\t{gnr.shape[0]}\\t4\\t2\\n')\n",
    "        datfile.write(\"\\n\".join(\"\".join(map(str, x)) for x in pos_string)) \n",
    "        datfile.write(\"\\n\")\n",
    "        datfile.write(\"\\n\".join(\"\\t\".join(map(str, x)) for x in dat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------ LDNe_Ag -------------------------------\n",
      "\n",
      "Storing metadata in data/Phase3.LDNe.tsv\n",
      "\n",
      "Producing LDNe input for Bioko, 2002, gambiae, 3L. 10 individuals, (gambcolu filter)\n",
      "GenotypeArray shape before pruning - (370914, 10, 2)\n",
      "iteration 1 retaining 15426 removing 355488 variants\n",
      "Converting to .dat AG1000G-GQ Bioko 2002 gambiae 3L\n",
      "Writing .batch.txt file for LDNe...\n",
      "\n",
      "Producing LDNe input for Antula, 2010, gambiae, 3L. 15 individuals, (gambcolu filter)\n",
      "GenotypeArray shape before pruning - (468179, 15, 2)\n",
      "iteration 1 retaining 48151 removing 420028 variants\n",
      "Converting to .dat AG1000G-GW Antula 2010 gambiae 3L\n",
      "Writing .batch.txt file for LDNe...\n",
      "\n",
      "Producing LDNe input for Antula, 2010, intermediate, 3L. 45 individuals, (gambcolu filter)\n",
      "GenotypeArray shape before pruning - (423179, 45, 2)\n",
      "iteration 1 retaining 112829 removing 310350 variants\n",
      "Converting to .dat AG1000G-GW Antula 2010 intermediate 3L\n",
      "Writing .batch.txt file for LDNe...\n",
      "\n",
      "Producing LDNe input for Safim, 2010, intermediate, 3L. 27 individuals, (gambcolu filter)\n",
      "GenotypeArray shape before pruning - (464749, 27, 2)\n",
      "iteration 1 retaining 64181 removing 400568 variants\n",
      "Converting to .dat AG1000G-GW Safim 2010 intermediate 3L\n",
      "Writing .batch.txt file for LDNe...\n",
      "\n",
      "Producing LDNe input for Kilifi, 2012, arabiensis, 3L. 10 individuals, (arabiensis filter)\n",
      "GenotypeArray shape before pruning - (219726, 10, 2)\n",
      "iteration 1 retaining 13274 removing 206452 variants\n",
      "Converting to .dat AG1000G-KE Kilifi 2012 arabiensis 3L\n",
      "Writing .batch.txt file for LDNe...\n",
      "\n",
      "Producing LDNe input for Kilifi, 2012, intermediate, 3L. 45 individuals, (gambcolu filter)\n",
      "GenotypeArray shape before pruning - (261167, 45, 2)\n",
      "iteration 1 retaining 3383 removing 257784 variants\n",
      "Converting to .dat AG1000G-KE Kilifi 2012 intermediate 3L\n",
      "Writing .batch.txt file for LDNe...\n",
      "\n",
      "Producing LDNe input for Kilifi, 2012, gambiae, 3L. 9 individuals, (gambcolu filter)\n",
      "GenotypeArray shape before pruning - (281856, 9, 2)\n",
      "iteration 1 retaining 4162 removing 277694 variants\n",
      "Converting to .dat AG1000G-KE Kilifi 2012 gambiae 3L\n",
      "Writing .batch.txt file for LDNe...\n",
      "\n",
      "Producing LDNe input for Kilifi, 2000, gambiae, 3L. 19 individuals, (gambcolu filter)\n",
      "GenotypeArray shape before pruning - (454147, 19, 2)\n",
      "iteration 1 retaining 26616 removing 427531 variants\n",
      "Converting to .dat AG1000G-KE Kilifi 2000 gambiae 3L\n",
      "Writing .batch.txt file for LDNe...\n",
      "\n",
      "Producing LDNe input for Kababougou, 2014, coluzzii, 3L. 12 individuals, (gambcolu filter)\n",
      "GenotypeArray shape before pruning - (373905, 12, 2)\n",
      "iteration 1 retaining 33860 removing 340045 variants\n",
      "Converting to .dat AG1000G-ML-A Kababougou 2014 coluzzii 3L\n",
      "Writing .batch.txt file for LDNe...\n",
      "\n",
      "Producing LDNe input for Kababougou, 2014, gambiae, 3L. 28 individuals, (gambcolu filter)\n",
      "GenotypeArray shape before pruning - (438280, 28, 2)\n",
      "iteration 1 retaining 71831 removing 366449 variants\n",
      "Converting to .dat AG1000G-ML-A Kababougou 2014 gambiae 3L\n",
      "Writing .batch.txt file for LDNe...\n",
      "\n",
      "Producing LDNe input for Ouassorola, 2014, coluzzii, 3L. 9 individuals, (gambcolu filter)\n",
      "GenotypeArray shape before pruning - (710750, 9, 2)\n",
      "iteration 1 retaining 21918 removing 688832 variants\n",
      "Converting to .dat AG1000G-ML-A Ouassorola 2014 coluzzii 3L\n",
      "Writing .batch.txt file for LDNe...\n",
      "\n",
      "Producing LDNe input for Bancoumana, 2004, gambiae, 3L. 9 individuals, (gambcolu filter)\n",
      "GenotypeArray shape before pruning - (720083, 9, 2)\n",
      "iteration 1 retaining 22447 removing 697636 variants\n",
      "Converting to .dat AG1000G-ML-B Bancoumana 2004 gambiae 3L\n",
      "Writing .batch.txt file for LDNe...\n",
      "\n",
      "Producing LDNe input for Kela, 2004, gambiae, 3L. 23 individuals, (gambcolu filter)\n",
      "GenotypeArray shape before pruning - (399571, 23, 2)\n",
      "iteration 1 retaining 42457 removing 357114 variants\n",
      "Converting to .dat AG1000G-ML-B Kela 2004 gambiae 3L\n",
      "Writing .batch.txt file for LDNe...\n",
      "\n",
      "Producing LDNe input for Douna, 2004, coluzzii, 3L. 19 individuals, (gambcolu filter)\n",
      "GenotypeArray shape before pruning - (498937, 19, 2)\n",
      "iteration 1 retaining 69907 removing 429030 variants\n",
      "Converting to .dat AG1000G-ML-B Douna 2004 coluzzii 3L\n",
      "Writing .batch.txt file for LDNe...\n",
      "\n",
      "Producing LDNe input for Chikhwawa, 2015, arabiensis, 3L. 41 individuals, (arabiensis filter)\n",
      "GenotypeArray shape before pruning - (252315, 41, 2)\n",
      "iteration 1 retaining 47378 removing 204937 variants\n",
      "Converting to .dat AG1000G-MW Chikhwawa 2015 arabiensis 3L\n",
      "Writing .batch.txt file for LDNe...\n",
      "\n",
      "Producing LDNe input for Furvela, 2004, gambiae, 3L. 71 individuals, (gambcolu filter)\n",
      "GenotypeArray shape before pruning - (384790, 71, 2)\n",
      "iteration 1 retaining 26090 removing 358700 variants\n",
      "Converting to .dat AG1000G-MZ Furvela 2004 gambiae 3L\n",
      "Writing .batch.txt file for LDNe...\n",
      "\n",
      "Producing LDNe input for Muleba, 2015, arabiensis, 3L. 137 individuals, (arabiensis filter)\n",
      "GenotypeArray shape before pruning - (262957, 137, 2)\n",
      "iteration 1 retaining 90597 removing 172360 variants\n",
      "Converting to .dat AG1000G-TZ Muleba 2015 arabiensis 3L\n",
      "Writing .batch.txt file for LDNe...\n",
      "\n",
      "Producing LDNe input for Muleba, 2015, gambiae, 3L. 32 individuals, (gambcolu filter)\n",
      "GenotypeArray shape before pruning - (399197, 32, 2)\n",
      "iteration 1 retaining 67270 removing 331927 variants\n",
      "Converting to .dat AG1000G-TZ Muleba 2015 gambiae 3L\n",
      "Writing .batch.txt file for LDNe...\n",
      "\n",
      "Producing LDNe input for Moshi, 2012, arabiensis, 3L. 40 individuals, (arabiensis filter)\n",
      "GenotypeArray shape before pruning - (247758, 40, 2)\n",
      "iteration 1 retaining 44017 removing 203741 variants\n",
      "Converting to .dat AG1000G-TZ Moshi 2012 arabiensis 3L\n",
      "Writing .batch.txt file for LDNe...\n",
      "\n",
      "Producing LDNe input for Tarime, 2012, arabiensis, 3L. 47 individuals, (arabiensis filter)\n",
      "GenotypeArray shape before pruning - (268216, 47, 2)\n",
      "iteration 1 retaining 59507 removing 208709 variants\n",
      "Converting to .dat AG1000G-TZ Tarime 2012 arabiensis 3L\n",
      "Writing .batch.txt file for LDNe...\n",
      "\n",
      "Producing LDNe input for Muheza, 2013, gambiae, 3L. 36 individuals, (gambcolu filter)\n",
      "GenotypeArray shape before pruning - (430408, 36, 2)\n",
      "iteration 1 retaining 32756 removing 397652 variants\n",
      "Converting to .dat AG1000G-TZ Muheza 2013 gambiae 3L\n",
      "Writing .batch.txt file for LDNe...\n",
      "\n",
      "Producing LDNe input for Nagongera, 2012, arabiensis, 3L. 81 individuals, (arabiensis filter)\n",
      "GenotypeArray shape before pruning - (252641, 81, 2)\n",
      "iteration 1 retaining 76742 removing 175899 variants\n",
      "Converting to .dat AG1000G-UG Nagongera 2012 arabiensis 3L\n",
      "Writing .batch.txt file for LDNe...\n",
      "\n",
      "Producing LDNe input for Nagongera, 2012, gambiae, 3L. 112 individuals, (gambcolu filter)\n",
      "GenotypeArray shape before pruning - (363874, 112, 2)\n",
      "iteration 1 retaining 172286 removing 191588 variants\n",
      "Converting to .dat AG1000G-UG Nagongera 2012 gambiae 3L\n",
      "Writing .batch.txt file for LDNe...\n",
      "\n",
      "Producing LDNe input for Kihihi, 2012, gambiae, 3L. 95 individuals, (gambcolu filter)\n",
      "GenotypeArray shape before pruning - (390464, 95, 2)\n",
      "iteration 1 retaining 155062 removing 235402 variants\n",
      "Converting to .dat AG1000G-UG Kihihi 2012 gambiae 3L\n",
      "Writing .batch.txt file for LDNe...\n",
      "------------------------ LDNe_Ag -------------------------------\n",
      "\n",
      "Storing metadata in data/Phase3.LDNe.tsv\n",
      "\n",
      "Producing LDNe input for Luanda, 2009, coluzzii, 3R. 81 individuals, (gambcolu filter)\n",
      "GenotypeArray shape before pruning - (462740, 81, 2)\n",
      "iteration 1 retaining 60876 removing 401864 variants\n",
      "Converting to .dat AG1000G-AO Luanda 2009 coluzzii 3R\n",
      "Writing .batch.txt file for LDNe...\n",
      "\n",
      "Producing LDNe input for Pala, 2012, gambiae, 3R. 48 individuals, (gambcolu filter)\n",
      "GenotypeArray shape before pruning - (531382, 48, 2)\n",
      "iteration 1 retaining 164595 removing 366787 variants\n",
      "Converting to .dat AG1000G-BF-A Pala 2012 gambiae 3R\n",
      "Writing .batch.txt file for LDNe...\n",
      "\n",
      "Producing LDNe input for Pala, 2012, coluzzii, 3R. 11 individuals, (gambcolu filter)\n",
      "GenotypeArray shape before pruning - (452204, 11, 2)\n",
      "iteration 1 retaining 34870 removing 417334 variants\n",
      "Converting to .dat AG1000G-BF-A Pala 2012 coluzzii 3R\n",
      "Writing .batch.txt file for LDNe...\n",
      "\n",
      "Producing LDNe input for Bana, 2012, coluzzii, 3R. 42 individuals, (gambcolu filter)\n",
      "GenotypeArray shape before pruning - (469829, 42, 2)\n",
      "iteration 1 retaining 140917 removing 328912 variants\n",
      "Converting to .dat AG1000G-BF-A Bana 2012 coluzzii 3R\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing .batch.txt file for LDNe...\n",
      "\n",
      "Producing LDNe input for Bana, 2012, gambiae, 3R. 22 individuals, (gambcolu filter)\n",
      "GenotypeArray shape before pruning - (499457, 22, 2)\n",
      "iteration 1 retaining 52242 removing 447215 variants\n",
      "Converting to .dat AG1000G-BF-A Bana 2012 gambiae 3R\n",
      "Writing .batch.txt file for LDNe...\n",
      "\n",
      "Producing LDNe input for Souroukoudinga, 2012, coluzzii, 3R. 29 individuals, (gambcolu filter)\n",
      "GenotypeArray shape before pruning - (570995, 29, 2)\n",
      "iteration 1 retaining 99569 removing 471426 variants\n",
      "Converting to .dat AG1000G-BF-A Souroukoudinga 2012 coluzzii 3R\n",
      "Writing .batch.txt file for LDNe...\n",
      "\n",
      "Producing LDNe input for Souroukoudinga, 2012, gambiae, 3R. 28 individuals, (gambcolu filter)\n",
      "GenotypeArray shape before pruning - (584028, 28, 2)\n",
      "iteration 1 retaining 89667 removing 494361 variants\n",
      "Converting to .dat AG1000G-BF-A Souroukoudinga 2012 gambiae 3R\n",
      "Writing .batch.txt file for LDNe...\n",
      "\n",
      "Producing LDNe input for Bana, 2014, coluzzii, 3R. 47 individuals, (gambcolu filter)\n",
      "GenotypeArray shape before pruning - (503740, 47, 2)\n",
      "iteration 1 retaining 169518 removing 334222 variants\n",
      "Converting to .dat AG1000G-BF-B Bana 2014 coluzzii 3R\n",
      "Writing .batch.txt file for LDNe...\n",
      "\n",
      "Producing LDNe input for Bana, 2014, gambiae, 3R. 15 individuals, (gambcolu filter)\n",
      "GenotypeArray shape before pruning - (576270, 15, 2)\n",
      "iteration 1 retaining 64119 removing 512151 variants\n",
      "Converting to .dat AG1000G-BF-B Bana 2014 gambiae 3R\n",
      "Writing .batch.txt file for LDNe...\n",
      "\n",
      "Producing LDNe input for Pala, 2014, gambiae, 3R. 16 individuals, (gambcolu filter)\n",
      "GenotypeArray shape before pruning - (624937, 16, 2)\n",
      "iteration 1 retaining 67726 removing 557211 variants\n",
      "Converting to .dat AG1000G-BF-B Pala 2014 gambiae 3R\n",
      "Writing .batch.txt file for LDNe...\n",
      "\n",
      "Producing LDNe input for Souroukoudinga, 2014, gambiae, 3R. 15 individuals, (gambcolu filter)\n",
      "GenotypeArray shape before pruning - (577342, 15, 2)\n",
      "iteration 1 retaining 64862 removing 512480 variants\n",
      "Converting to .dat AG1000G-BF-B Souroukoudinga 2014 gambiae 3R\n",
      "Writing .batch.txt file for LDNe...\n",
      "\n",
      "Producing LDNe input for Monomtenga, 2004, gambiae, 3R. 13 individuals, (gambcolu filter)\n",
      "GenotypeArray shape before pruning - (523022, 13, 2)\n",
      "iteration 1 retaining 47068 removing 475954 variants\n",
      "Converting to .dat AG1000G-BF-C Monomtenga 2004 gambiae 3R\n",
      "Writing .batch.txt file for LDNe...\n",
      "\n",
      "Producing LDNe input for Gbadolite, 2015, gambiae, 3R. 76 individuals, (gambcolu filter)\n",
      "GenotypeArray shape before pruning - (492195, 76, 2)\n",
      "iteration 1 retaining 206228 removing 285967 variants\n",
      "Converting to .dat AG1000G-CD Gbadolite 2015 gambiae 3R\n",
      "Writing .batch.txt file for LDNe...\n",
      "\n",
      "Producing LDNe input for Bangui, 1994, gambiae, 3R. 53 individuals, (gambcolu filter)\n",
      "GenotypeArray shape before pruning - (483078, 53, 2)\n",
      "iteration 1 retaining 181219 removing 301859 variants\n",
      "Converting to .dat AG1000G-CF Bangui 1994 gambiae 3R\n",
      "Writing .batch.txt file for LDNe...\n",
      "\n",
      "Producing LDNe input for Bangui, 1994, coluzzii, 3R. 13 individuals, (gambcolu filter)\n",
      "GenotypeArray shape before pruning - (495618, 13, 2)\n",
      "iteration 1 retaining 44748 removing 450870 variants\n",
      "Converting to .dat AG1000G-CF Bangui 1994 coluzzii 3R\n",
      "Writing .batch.txt file for LDNe...\n",
      "\n",
      "Producing LDNe input for Tiassale, 2012, coluzzii, 3R. 80 individuals, (gambcolu filter)\n",
      "GenotypeArray shape before pruning - (508872, 80, 2)\n",
      "iteration 1 retaining 150041 removing 358831 variants\n",
      "Converting to .dat AG1000G-CI Tiassale 2012 coluzzii 3R\n",
      "Writing .batch.txt file for LDNe...\n",
      "\n",
      "Producing LDNe input for Mayos, 2009, gambiae, 3R. 110 individuals, (gambcolu filter)\n"
     ]
    }
   ],
   "source": [
    "for chrom in chroms:\n",
    "\n",
    "    print(f\"------------------------ LDNe_Ag -------------------------------\\n\")\n",
    "    print(f\"Storing metadata in data/Phase3.LDNe.tsv\")\n",
    "    #with open('../data/Phase3.LDNe.tsv', 'w') as metafile:\n",
    "    #    metafile.write(\"sample_set\\tlocation\\tyear\\tspecies\\tchromosome\\n\")\n",
    " \n",
    "        \n",
    "    #filter the gff3 to be coding and regulatory regions\n",
    "    df = allel.gff3_to_dataframe(f\"{argsgff}\")\n",
    "    coding_reg_df = df[~df.type.isin(['chromosome', 'three_prime_UTR','five_prime_UTR',\n",
    "                    'mRNA', 'CDS', 'exon'])].drop(columns=['source', 'strand', 'phase', 'score'])\n",
    "    coding_reg_df = coding_reg_df[coding_reg_df.seqid == chrom]\n",
    "\n",
    "    for _set in all_sets:\n",
    "    \n",
    "        #subset metadata\n",
    "        metadata = manifest[manifest.sample_set == _set].reset_index(drop=True)\n",
    "\n",
    "        ### loop through combos \n",
    "        for loc in metadata.location.unique():\n",
    "\n",
    "            nmeta = metadata[metadata.location == loc]\n",
    "\n",
    "            for yr in nmeta.year.unique():\n",
    "\n",
    "                nmeta2 = nmeta[nmeta.year == yr]\n",
    "                \n",
    "                #have edited .species_gambiae_coluzzii column to contain arabiensis instead of NA \n",
    "                for sp in nmeta2.species_gambiae_coluzzii.unique():\n",
    "                    \n",
    "                    # if file exists ignore and skip\n",
    "                    myfile = Path(f\"../data/dat/{_set}.{loc}.{yr}.{sp}.{chrom}.dat\")\n",
    "                    if myfile.is_file():\n",
    "                        continue\n",
    "\n",
    "                    #if there is less than 9 samples than skip\n",
    "                    if (nmeta2.species_gambiae_coluzzii == sp).sum() <= 8:\n",
    "                        continue\n",
    "                    \n",
    "                    #need to implement separate site filters for arabiensis v gamb_colu \n",
    "                    if sp == 'arabiensis':  \n",
    "                        geno, positions = load_arrays_noncoding_and_centromeres(local_path,_set, chrom, coding_reg_df, sitefilter='arab')\n",
    "                        #filter to species \n",
    "                        nmeta3 = nmeta2[nmeta2.species_gambiae_coluzzii == sp]\n",
    "                        flt = np.array(nmeta3.index)\n",
    "                        #filter to correct loc, year, species individuals\n",
    "                        gn = geno.take(flt, axis=1)\n",
    "                        \n",
    "                        print(f\"\\nProducing LDNe input for {loc}, {yr}, {sp}, {chrom}. {nmeta3.shape[0]} individuals, (arabiensis filter)\")\n",
    "                        convert2dat(gn, positions, n, _set, loc, yr, sp, chrom)\n",
    "                \n",
    "                    else:\n",
    "                        geno, positions = load_arrays_noncoding_and_centromeres(local_path, _set, chrom, coding_reg_df, sitefilter='gamb_colu')\n",
    "                        #filter to species \n",
    "                        nmeta3 = nmeta2[nmeta2.species_gambiae_coluzzii == sp]\n",
    "                        flt = np.array(nmeta3.index)\n",
    "                        #filter to correct loc, year, species individuals\n",
    "                        gn = geno.take(flt, axis=1)   \n",
    "                        \n",
    "                        print(f\"\\nProducing LDNe input for {loc}, {yr}, {sp}, {chrom}. {nmeta3.shape[0]} individuals, (gambcolu filter)\")\n",
    "                        convert2dat(gn, positions, n, _set, loc, yr, sp, chrom)\n",
    "                        \n",
    "                    #write metadata file for samples that are included\n",
    "                    with open('../data/Phase3.LDNe.tsv', 'a') as metafile:\n",
    "                        metafile.write(f'{_set}\\t{loc}\\t{yr}\\t{sp}\\t{chrom}\\n')\n",
    "                    \n",
    "                    #write batch file for LDNe \n",
    "                    print(\"Writing .batch.txt file for LDNe...\")\n",
    "                    with open(f'../analysis/LDNe/batch/{_set}.{loc}.{yr}.{sp}.{chrom}.batch.txt', 'w') as batch_file:\n",
    "                        batch_file.write(f'1\\t0\\n1\\n0.05\\t-1\\n15\\t0\\t1\\n1\\n0\\n0\\n0\\n0\\nanalysis/LDNe/Ag_LDNe_{_set}.{loc}.{yr}.{sp}.{chrom}.out\\n')\n",
    "                        batch_file.write(f\"data/dat/{_set}.{loc}.{yr}.{sp}.{chrom}.dat\\n\")\n",
    "                        batch_file.write(\"*\")\n",
    "                        batch_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

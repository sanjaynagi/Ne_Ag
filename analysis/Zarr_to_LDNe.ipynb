{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import zarr\n",
    "import allel\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zarr2LDNe\n",
    " \n",
    "       Sanjay C Nagi      06/07/20\n",
    "\n",
    "I have written a snakemake pipeline which subsets and downsamples the zarr genotype arrays in phase 2, and runs LDNe on the populations within. I now want to run this on all of phase 3. As phase 3 is grouped by sample_set, I want to run LDNe on all locations + years that have greater than 15 samples, though this number is currently arbitrary.\n",
    "\n",
    "Which groups of samples do we want to run LDNe on? see below...\n",
    "### Phase 3 samples for LDNe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "manifest = pd.read_csv(\"../../data/phase3/Ag1000g.phase3.manifest.tsv\", sep=\"\\t\")\n",
    "#manifest[manifest.n_samples >= 15]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The idea here would be to (in snakemake) loop through each sample_set (not shown above), then within each sample set loop through each location and finally year, where there is temporal samples. \n",
    "\n",
    "At each point we need to extract the appropriate genotypes from the sample set zarrs. We'll also need to filter SNPs, and then can run the downstream LDNe prep."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "manifest = pd.read_csv(\"../../data/phase3/Ag1000g.phase3.manifest.full.tsv\", sep=\"\\t\")\n",
    "manifest.location = [loc.replace(\" \", \"\") for loc in manifest.location]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Phase 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_sets = manifest.sample_set.unique()\n",
    "\n",
    "chroms = ['3L','3R']\n",
    "n = 20000\n",
    "argsgff = \"../data/An.gambiae-PEST-BASEFEATURES_agamP4.12.gff3.gz\"\n",
    "\n",
    "local_path = Path(\"/home/sanj/ag1000g/data/phase3/\").expanduser() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------ LDNe_Ag -------------------------------\n",
      "\n",
      "Storing metadata in data/Phase3.LDNe.tsv\n",
      "\n",
      "Producing LDNe input for Monomtenga, 2004, gambiae, 3L. 13 individuals, (gambcolu filter)\n",
      "Converting to .dat AG1000G-BF-C Monomtenga 2004 gambiae 3L\n",
      "Writing .batch.txt file for LDNe...\n",
      "\n",
      "Producing LDNe input for Bangui, 1994, coluzzii, 3L. 13 individuals, (gambcolu filter)\n",
      "Converting to .dat AG1000G-CF Bangui 1994 coluzzii 3L\n",
      "Writing .batch.txt file for LDNe...\n",
      "\n",
      "Producing LDNe input for Manda, 2013, gambiae, 3L. 11 individuals, (gambcolu filter)\n",
      "Converting to .dat AG1000G-CM-C Manda 2013 gambiae 3L\n",
      "Writing .batch.txt file for LDNe...\n",
      "\n",
      "Producing LDNe input for Madina, 2012, gambiae, 3L. 13 individuals, (gambcolu filter)\n",
      "Converting to .dat AG1000G-GH Madina 2012 gambiae 3L\n",
      "Writing .batch.txt file for LDNe...\n",
      "\n",
      "Producing LDNe input for Madina, 2012, coluzzii, 3L. 14 individuals, (gambcolu filter)\n",
      "Converting to .dat AG1000G-GH Madina 2012 coluzzii 3L\n",
      "Writing .batch.txt file for LDNe...\n",
      "\n",
      "Producing LDNe input for Njabakunda, 2011, intermediate, 3L. 11 individuals, (gambcolu filter)\n",
      "Converting to .dat AG1000G-GM-A Njabakunda 2011 intermediate 3L\n",
      "Writing .batch.txt file for LDNe...\n",
      "\n",
      "Producing LDNe input for Tankular, 2012, coluzzii, 3L. 14 individuals, (gambcolu filter)\n",
      "Converting to .dat AG1000G-GM-B Tankular 2012 coluzzii 3L\n",
      "Writing .batch.txt file for LDNe...\n",
      "\n",
      "Producing LDNe input for SareSambaSowe, 2012, gambiae, 3L. 9 individuals, (gambcolu filter)\n",
      "Converting to .dat AG1000G-GM-B SareSambaSowe 2012 gambiae 3L\n",
      "Writing .batch.txt file for LDNe...\n",
      "\n",
      "Producing LDNe input for Bioko, 2002, gambiae, 3L. 10 individuals, (gambcolu filter)\n",
      "Converting to .dat AG1000G-GQ Bioko 2002 gambiae 3L\n",
      "Writing .batch.txt file for LDNe...\n",
      "\n",
      "Producing LDNe input for Kilifi, 2012, arabiensis, 3L. 10 individuals, (arabiensis filter)\n",
      "Converting to .dat AG1000G-KE Kilifi 2012 arabiensis 3L\n",
      "Writing .batch.txt file for LDNe...\n",
      "\n",
      "Producing LDNe input for Kilifi, 2012, gambiae, 3L. 9 individuals, (gambcolu filter)\n",
      "Converting to .dat AG1000G-KE Kilifi 2012 gambiae 3L\n",
      "Writing .batch.txt file for LDNe...\n",
      "\n",
      "Producing LDNe input for Kababougou, 2014, coluzzii, 3L. 12 individuals, (gambcolu filter)\n",
      "Converting to .dat AG1000G-ML-A Kababougou 2014 coluzzii 3L\n",
      "Writing .batch.txt file for LDNe...\n",
      "\n",
      "Producing LDNe input for Ouassorola, 2014, coluzzii, 3L. 9 individuals, (gambcolu filter)\n",
      "Converting to .dat AG1000G-ML-A Ouassorola 2014 coluzzii 3L\n",
      "Writing .batch.txt file for LDNe...\n",
      "\n",
      "Producing LDNe input for Bancoumana, 2004, gambiae, 3L. 9 individuals, (gambcolu filter)\n",
      "Converting to .dat AG1000G-ML-B Bancoumana 2004 gambiae 3L\n",
      "Writing .batch.txt file for LDNe...\n",
      "------------------------ LDNe_Ag -------------------------------\n",
      "\n",
      "Storing metadata in data/Phase3.LDNe.tsv\n",
      "\n",
      "Producing LDNe input for Pala, 2012, coluzzii, 3R. 11 individuals, (gambcolu filter)\n",
      "Converting to .dat AG1000G-BF-A Pala 2012 coluzzii 3R\n",
      "Writing .batch.txt file for LDNe...\n",
      "\n",
      "Producing LDNe input for Monomtenga, 2004, gambiae, 3R. 13 individuals, (gambcolu filter)\n",
      "Converting to .dat AG1000G-BF-C Monomtenga 2004 gambiae 3R\n",
      "Writing .batch.txt file for LDNe...\n",
      "\n",
      "Producing LDNe input for Bangui, 1994, coluzzii, 3R. 13 individuals, (gambcolu filter)\n",
      "Converting to .dat AG1000G-CF Bangui 1994 coluzzii 3R\n",
      "Writing .batch.txt file for LDNe...\n",
      "\n",
      "Producing LDNe input for Manda, 2013, gambiae, 3R. 11 individuals, (gambcolu filter)\n",
      "Converting to .dat AG1000G-CM-C Manda 2013 gambiae 3R\n",
      "Writing .batch.txt file for LDNe...\n",
      "\n",
      "Producing LDNe input for Madina, 2012, gambiae, 3R. 13 individuals, (gambcolu filter)\n",
      "Converting to .dat AG1000G-GH Madina 2012 gambiae 3R\n",
      "Writing .batch.txt file for LDNe...\n",
      "\n",
      "Producing LDNe input for Madina, 2012, coluzzii, 3R. 14 individuals, (gambcolu filter)\n",
      "Converting to .dat AG1000G-GH Madina 2012 coluzzii 3R\n",
      "Writing .batch.txt file for LDNe...\n",
      "\n",
      "Producing LDNe input for Njabakunda, 2011, intermediate, 3R. 11 individuals, (gambcolu filter)\n",
      "Converting to .dat AG1000G-GM-A Njabakunda 2011 intermediate 3R\n",
      "Writing .batch.txt file for LDNe...\n",
      "\n",
      "Producing LDNe input for Tankular, 2012, coluzzii, 3R. 14 individuals, (gambcolu filter)\n",
      "Converting to .dat AG1000G-GM-B Tankular 2012 coluzzii 3R\n",
      "Writing .batch.txt file for LDNe...\n",
      "\n",
      "Producing LDNe input for SareSambaSowe, 2012, gambiae, 3R. 9 individuals, (gambcolu filter)\n",
      "Converting to .dat AG1000G-GM-B SareSambaSowe 2012 gambiae 3R\n",
      "Writing .batch.txt file for LDNe...\n",
      "\n",
      "Producing LDNe input for Bioko, 2002, gambiae, 3R. 10 individuals, (gambcolu filter)\n",
      "Converting to .dat AG1000G-GQ Bioko 2002 gambiae 3R\n",
      "Writing .batch.txt file for LDNe...\n",
      "\n",
      "Producing LDNe input for Kilifi, 2012, arabiensis, 3R. 10 individuals, (arabiensis filter)\n",
      "Converting to .dat AG1000G-KE Kilifi 2012 arabiensis 3R\n",
      "Writing .batch.txt file for LDNe...\n",
      "\n",
      "Producing LDNe input for Kilifi, 2012, gambiae, 3R. 9 individuals, (gambcolu filter)\n",
      "Converting to .dat AG1000G-KE Kilifi 2012 gambiae 3R\n",
      "Writing .batch.txt file for LDNe...\n",
      "\n",
      "Producing LDNe input for Kababougou, 2014, coluzzii, 3R. 12 individuals, (gambcolu filter)\n",
      "Converting to .dat AG1000G-ML-A Kababougou 2014 coluzzii 3R\n",
      "Writing .batch.txt file for LDNe...\n",
      "\n",
      "Producing LDNe input for Ouassorola, 2014, coluzzii, 3R. 9 individuals, (gambcolu filter)\n",
      "Converting to .dat AG1000G-ML-A Ouassorola 2014 coluzzii 3R\n",
      "Writing .batch.txt file for LDNe...\n",
      "\n",
      "Producing LDNe input for Bancoumana, 2004, gambiae, 3R. 9 individuals, (gambcolu filter)\n",
      "Converting to .dat AG1000G-ML-B Bancoumana 2004 gambiae 3R\n",
      "Writing .batch.txt file for LDNe...\n"
     ]
    }
   ],
   "source": [
    "for chrom in chroms:\n",
    "\n",
    "    print(f\"------------------------ LDNe_Ag -------------------------------\\n\")\n",
    "    print(f\"Storing metadata in data/Phase3.LDNe.tsv\")\n",
    "    with open('../data/Phase3.LDNe.tsv', 'w') as metafile:\n",
    "        metafile.write(\"sample_set\\tlocation\\tyear\\tspecies\\tchromosome\\n\")\n",
    " \n",
    "        \n",
    "    #filter the gff3 to be coding and regulatory regions\n",
    "    df = allel.gff3_to_dataframe(f\"{argsgff}\")\n",
    "    coding_reg_df = df[~df.type.isin(['chromosome', 'three_prime_UTR','five_prime_UTR',\n",
    "                    'mRNA', 'CDS', 'exon'])].drop(columns=['source', 'strand', 'phase', 'score'])\n",
    "    coding_reg_df = coding_reg_df[coding_reg_df.seqid == chrom]\n",
    "\n",
    "    for _set in all_sets:\n",
    "    \n",
    "        #subset metadata\n",
    "        metadata = manifest[manifest.sample_set == _set].reset_index(drop=True)\n",
    "\n",
    "        ### loop through combos \n",
    "        for loc in metadata.location.unique():\n",
    "\n",
    "            nmeta = metadata[metadata.location == loc]\n",
    "\n",
    "            for yr in nmeta.year.unique():\n",
    "\n",
    "                nmeta2 = nmeta[nmeta.year == yr]\n",
    "                \n",
    "                #have edited .species_gambiae_coluzzii column to contain arabiensis instead of NA \n",
    "                for sp in nmeta2.species_gambiae_coluzzii.unique():\n",
    "                    \n",
    "                    # file exists so ignore and skip\n",
    "                    myfile = Path(f\"../data/dat/{_set}.{loc}.{yr}.{sp}.{chrom}.dat\")\n",
    "                    if myfile.is_file():\n",
    "                        continue\n",
    "\n",
    "                    #if there is less than 9 samples than skip\n",
    "                    if (nmeta2.species_gambiae_coluzzii == sp).sum() <= 8:\n",
    "                        continue\n",
    "                    \n",
    "                    if sp == 'arabiensis':  \n",
    "                        geno, positions = load_arrays_noncoding_and_centromeres(local_path,_set, chrom, coding_reg_df, sitefilter='arab')\n",
    "                        #filter to species \n",
    "                        nmeta3 = nmeta2[nmeta2.species_gambiae_coluzzii == sp]\n",
    "                        flt = np.array(nmeta3.index)\n",
    "                        #filter to correct loc, year, species individuals\n",
    "                        gn = geno.take(flt, axis=1)\n",
    "                        print(f\"\\nProducing LDNe input for {loc}, {yr}, {sp}, {chrom}. {nmeta3.shape[0]} individuals, (arabiensis filter)\")\n",
    "\n",
    "                        convert2dat(gn, positions, n, _set, loc, yr, sp, chrom)\n",
    "                \n",
    "                    else:\n",
    "                        geno, positions = load_arrays_noncoding_and_centromeres(local_path, _set, chrom, coding_reg_df, sitefilter='gamb_colu')\n",
    "                        #filter to species \n",
    "                        nmeta3 = nmeta2[nmeta2.species_gambiae_coluzzii == sp]\n",
    "                        flt = np.array(nmeta3.index)\n",
    "                        #filter to correct loc, year, species individuals\n",
    "                        gn = geno.take(flt, axis=1)\n",
    "                        print(f\"\\nProducing LDNe input for {loc}, {yr}, {sp}, {chrom}. {nmeta3.shape[0]} individuals, (gambcolu filter)\")\n",
    "\n",
    "                        convert2dat(gn, positions, n, _set, loc, yr, sp, chrom)\n",
    "\n",
    "                    #write metadata file for samples that are included\n",
    "                    with open('../data/Phase3.LDNe.tsv', 'a') as metafile:\n",
    "                        metafile.write(f'{_set}\\t{loc}\\t{yr}\\t{sp}\\t{chrom}\\n')\n",
    "                    \n",
    "                    print(\"Writing .batch.txt file for LDNe...\")\n",
    "                    with open(f'../analysis/LDNe/batch/{_set}.{loc}.{yr}.{sp}.{chrom}.batch.txt', 'w') as batch_file:\n",
    "                        batch_file.write(f'1\\t0\\n1\\n0.05\\t-1\\n15\\t0\\t1\\n1\\n0\\n0\\n0\\n0\\nanalysis/LDNe/Ag_LDNe_{_set}.{loc}.{yr}.{sp}.{chrom}.out\\n')\n",
    "                        batch_file.write(f\"data/dat/{_set}.{loc}.{yr}.{sp}.{chrom}.dat\\n\")\n",
    "                        batch_file.write(\"*\")\n",
    "                        batch_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### functions #####\n",
    "def load_arrays_noncoding_and_centromeres(local_path, _set, chrom, coding_reg_df, sitefilter='gamb_colu'):\n",
    "    \n",
    "    \"\"\"\n",
    "    This function reads and filters a genotyping array to the noncoding, noncentromeric regions, and applys a filter depending on \n",
    "    whether the samples are arabiensis (arab) or gambiae/coluzzii (gamb_colu)\n",
    "    \"\"\"\n",
    "    \n",
    "    Ag_array = zarr.open_array(f\"{local_path}/snp_genotypes/all/{_set}/{chrom}/calldata/GT/\", mode = 'r')\n",
    "    filters = zarr.open(f\"{local_path}/site_filters/dt_20200416/{sitefilter}/{chrom}/variants/filter_pass\", mode=\"r\")\n",
    "    positions = zarr.open_array(f\"{local_path}/snp_genotypes/all/sites/{chrom}/variants/POS/\", mode='r')\n",
    "    positions = positions[:][filters[:]]    \n",
    "    geno = allel.GenotypeDaskArray(Ag_array)\n",
    "    geno = geno[filters[:]]\n",
    "    \n",
    "    if chrom == '2L':\n",
    "        centromere = (positions > 3000000)\n",
    "    elif chrom == '2R':\n",
    "        centromere = (positions < 57000000)\n",
    "    elif chrom == '3L':\n",
    "        centromere = (positions > 2000000)\n",
    "    elif chrom == '3R':\n",
    "        centromere = (positions < 50000000)\n",
    "    elif chrom == 'X':\n",
    "        centromere = (positions < 21000000) \n",
    "        \n",
    "    positions = allel.SortedIndex(positions[centromere])\n",
    "    #get boolean array for positions that are coding - allel.locate_ranges so fast!\n",
    "    coding = positions.locate_ranges(coding_reg_df.start, coding_reg_df.end, strict=False)\n",
    "    #compress to get noncoding SNPs and remove centromeric regions of low recombination\n",
    "    #get non-centromeric regions. currently chosen by eye based on ag1000g phase1 paper fig1.\n",
    "  \n",
    "    #TODO currently using all non-coding regions, alternate option may be to take SNPs x distance from coding regions \n",
    "    geno = geno.compress(centromere, axis=0)\n",
    "    geno = geno.compress(~coding, axis=0) #we want noncoding regions so '~' to get inverse of boolean\n",
    "    positions = positions[~coding]\n",
    "    \n",
    "    return(geno, positions)\n",
    "\n",
    "def convert2dat(gn, positions, n, _set, loc, yr, sp, chrom):\n",
    "    \n",
    "    \"\"\"\n",
    "    This function takes a genotyping array and positions, along with info on the sample_set, location , year, species, chrom,\n",
    "    and converts the genotyping array into a .dat file, suitable for use with LDNe. It randomly downsamples the genotyping array\n",
    "    by n SNPs\n",
    "    \"\"\"\n",
    "    \n",
    "    # MAF 0.05 filter\n",
    "    ac = gn.count_alleles()\n",
    "    freqs = ac.to_frequencies().compute()\n",
    "    ALT1 = freqs[:,1] > 0.05\n",
    "    ALT2 = freqs[:,2] > 0.05\n",
    "    ALT3 = freqs[:,3] > 0.05\n",
    "    maf_flt = np.logical_or(ALT1, ALT2, ALT3)\n",
    "    gn = gn.compress(maf_flt, axis=0)\n",
    "\n",
    "    #take random sample of n SNPs \n",
    "    snp_sample = np.random.choice(gn.shape[0], n, replace=False)\n",
    "    snp_sample.sort()\n",
    "    gnr = gn.take(snp_sample, axis=0)\n",
    "    gnr = np.array(gnr[:])\n",
    "    gnr = gnr.astype(str)\n",
    "\n",
    "    pos = positions[maf_flt]\n",
    "    pos = pos[snp_sample]\n",
    "    prefix = f'{chrom}_'\n",
    "    pos_string = [prefix + p for p in pos.astype(str)]\n",
    "\n",
    "    gnr[gnr == '-1'] = '00' #convert missing alleles \n",
    "    dat = np.empty([gnr.shape[0], gnr.shape[1]])\n",
    "\n",
    "    #join genotypes in same individual \n",
    "    print(f\"Converting to .dat {_set} {loc} {yr} {sp} {chrom}\")\n",
    "    for x in range(gnr.shape[0]):\n",
    "        for y in range(gnr.shape[1]):\n",
    "            dat[x,y] = ''.join(gnr[x,y])\n",
    "\n",
    "    #convert to .dat format genotypes \n",
    "    dat = dat.astype(str)\n",
    "    dat[dat == '0.0'] = '0101'\n",
    "    dat[dat == '1.0'] = '0102'\n",
    "    dat[dat == '2.0'] = '0103'\n",
    "    dat[dat == '3.0'] = '0104'\n",
    "    dat[dat == '10.0'] = '0201'\n",
    "    dat[dat == '11.0'] = '0202'\n",
    "    dat[dat == '12.0'] = '0203'\n",
    "    dat[dat == '13.0'] = '0204'\n",
    "    dat[dat == '20.0'] = '0301'\n",
    "    dat[dat == '21.0'] = '0302'\n",
    "    dat[dat == '22.0'] = '0303'\n",
    "    dat[dat == '23.0'] = '0304'\n",
    "    dat[dat == '30.0'] = '0401'\n",
    "    dat[dat == '31.0'] = '0402'\n",
    "    dat[dat == '32.0'] = '0403'\n",
    "    dat[dat == '33.0'] = '0404'\n",
    "\n",
    "    #stack population name and transposed genotypes \n",
    "    popnames = np.repeat(f\"{_set}{loc}{yr}{sp}{chrom}\", gnr.shape[1])\n",
    "    dat = np.column_stack((popnames, dat.T)) #\n",
    "\n",
    "    #write out .dat file for LDNe \n",
    "    with open(f'../data/dat/{_set}.{loc}.{yr}.{sp}.{chrom}.dat', 'w') as datfile:\n",
    "        datfile.write(f'{gnr.shape[1]}\\t{gnr.shape[0]}\\t4\\t2\\n')\n",
    "        datfile.write(\"\\n\".join(\"\".join(map(str, x)) for x in pos_string)) \n",
    "        datfile.write(\"\\n\")\n",
    "        datfile.write(\"\\n\".join(\"\\t\".join(map(str, x)) for x in dat))\n",
    "        \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import zarr\n",
    "import allel\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zarr2LDNe\n",
    " \n",
    "       Sanjay C Nagi      06/07/20\n",
    "\n",
    "I have written a snakemake pipeline which subsets and downsamples the zarr genotype arrays in phase 2, and runs LDNe on the populations within. I now want to run this on all of phase 3. As phase 3 is grouped by sample_set, I want to run LDNe on all locations + years that have greater than 15 samples, though this number is currently arbitrary.\n",
    "\n",
    "Which groups of samples do we want to run LDNe on? see below...\n",
    "### Phase 3 samples for LDNe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "manifest = pd.read_csv(\"../../data/phase3/Ag1000g.phase3.manifest.tsv\", sep=\"\\t\")\n",
    "#manifest[manifest.n_samples >= 15]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The idea here would be to (in snakemake) loop through each sample_set (not shown above), then within each sample set loop through each location and finally year, where there is temporal samples. \n",
    "\n",
    "At each point we need to extract the appropriate genotypes from the sample set zarrs. We'll also need to filter SNPs, and then can run the downstream LDNe prep."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "manifest = pd.read_csv(\"../../data/phase3/Ag1000g.phase3.manifest.full.tsv\", sep=\"\\t\")\n",
    "manifest.location = [loc.replace(\" \", \"\") for loc in manifest.location]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Phase 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_sets = manifest.sample_set.unique()\n",
    "\n",
    "chroms = ['3L','3R']\n",
    "n = 20000\n",
    "argsgff = \"../data/An.gambiae-PEST-BASEFEATURES_agamP4.12.gff3.gz\"\n",
    "\n",
    "local_path = Path(\"/home/sanj/ag1000g/data/phase3/\").expanduser() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As phase 3 is organised into sample sets, I will loop through each sample set, and each location within that, each year within that, each species, producing FSTAT format files for LDNe, and writing out metadata along the way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### functions #####\n",
    "\n",
    "def ld_prune(gn, size, step, threshold=.2, n_iter=1, blen=10000):\n",
    "    \n",
    "    gn_alt = gn.to_n_alt()\n",
    "\n",
    "    for i in range(n_iter):\n",
    "        loc_unlinked = allel.locate_unlinked(gn_alt, size=size, step=step, threshold=threshold, blen=blen)\n",
    "        n = np.count_nonzero(loc_unlinked)\n",
    "        n_remove = gn.shape[0] - n\n",
    "        print('iteration', i+1, 'retaining', n, 'removing', n_remove, 'variants')\n",
    "        gn = gn.compress(loc_unlinked, axis=0)\n",
    "    return(gn, loc_unlinked)\n",
    "    \n",
    "\n",
    "def replace_with_dict2_generic(ar, dic, assume_all_present=False):\n",
    "    # Extract out keys and values\n",
    "    k = np.array(list(dic.keys()))\n",
    "    v = np.array(list(dic.values()))\n",
    "\n",
    "    # Get argsort indices\n",
    "    sidx = k.argsort()\n",
    "\n",
    "    ks = k[sidx]\n",
    "    vs = v[sidx]\n",
    "    idx = np.searchsorted(ks,ar)\n",
    "\n",
    "    if assume_all_present==0:\n",
    "        idx[idx==len(vs)] = 0\n",
    "        mask = ks[idx] == ar\n",
    "        return np.where(mask, vs[idx], ar)\n",
    "    else:\n",
    "        return vs[idx]\n",
    "    \n",
    "def load_arrays_noncoding_and_centromeres(local_path, _set, chrom, coding_reg_df, sitefilter='gamb_colu'):\n",
    "    \n",
    "    \"\"\"\n",
    "    This function reads and filters a genotyping array to the noncoding, noncentromeric regions, and applys a filter depending on \n",
    "    whether the samples are arabiensis (arab) or gambiae/coluzzii (gamb_colu)\n",
    "    \"\"\"\n",
    "    Ag_array = zarr.open_array(f\"{local_path}/snp_genotypes/all/{_set}/{chrom}/calldata/GT/\", mode = 'r')\n",
    "    filters = zarr.open(f\"{local_path}/site_filters/dt_20200416/{sitefilter}/{chrom}/variants/filter_pass\", mode=\"r\")\n",
    "    positions = zarr.open_array(f\"{local_path}/snp_genotypes/all/sites/{chrom}/variants/POS/\", mode='r')\n",
    "    positions = positions[:][filters[:]]    \n",
    "    geno = allel.GenotypeDaskArray(Ag_array)\n",
    "    geno = geno[filters[:]]\n",
    "    \n",
    "    if chrom == '2L':\n",
    "        centromere = (positions > 3000000)\n",
    "    elif chrom == '2R':\n",
    "        centromere = (positions < 57000000)\n",
    "    elif chrom == '3L':\n",
    "        centromere = (positions > 2000000)\n",
    "    elif chrom == '3R':\n",
    "        centromere = (positions < 50000000)\n",
    "    elif chrom == 'X':\n",
    "        centromere = (positions < 21000000) \n",
    "        \n",
    "    positions = allel.SortedIndex(positions[centromere])\n",
    "    #get boolean array for positions that are coding - allel.locate_ranges so fast!\n",
    "    coding = positions.locate_ranges(coding_reg_df.start, coding_reg_df.end, strict=False)\n",
    "    #compress to get noncoding SNPs and remove centromeric regions of low recombination\n",
    "    #get non-centromeric regions. currently chosen by eye based on ag1000g phase1 paper fig1.\n",
    "  \n",
    "    #TODO currently using all non-coding regions, alternate option may be to take SNPs x distance from coding regions \n",
    "    geno = geno.compress(centromere, axis=0)\n",
    "    geno = geno.compress(~coding, axis=0) #we want noncoding regions so '~' to get inverse of boolean\n",
    "    positions = positions[~coding]\n",
    "    \n",
    "    return(geno, positions)\n",
    "\n",
    "def convert2dat(gn, positions, n, _set, loc, yr, sp, chrom):\n",
    "    \n",
    "    \"\"\"\n",
    "    This function takes a genotyping array and positions, along with info on the sample_set, location , year, species, chrom,\n",
    "    and converts the genotyping array into a .dat file, suitable for use with LDNe. It randomly downsamples the genotyping array\n",
    "    by n SNPs\n",
    "    \"\"\"\n",
    "\n",
    "    # Biallelic and MAF 0.05 filter\n",
    "    ac = gn.count_alleles()\n",
    "    bial_ = ac.is_biallelic()\n",
    "    gn = gn.compress(bial_, axis=0)\n",
    "    ac = gn.count_alleles()\n",
    "    \n",
    "    freqs = ac.to_frequencies().compute()\n",
    "    ALT1 = freqs[:,1] > 0.05\n",
    "    ALT2 = freqs[:,2] > 0.05\n",
    "    ALT3 = freqs[:,3] > 0.05\n",
    "    maf_flt = np.logical_or(ALT1, ALT2, ALT3)\n",
    "    gn = gn.compress(maf_flt, axis=0)\n",
    "    \n",
    "    ## LD pruning\n",
    "    print(f\"GenotypeArray shape before pruning - {gn.shape}\")\n",
    "    gnu, loc_unlinked = ld_prune(gn, size=500, step=250, threshold=.2, n_iter=1, blen=10000)\n",
    "\n",
    "    #take random sample of n SNPs \n",
    "    snp_sample = np.random.choice(gnu.shape[0], n, replace=False)\n",
    "    snp_sample.sort()\n",
    "    gnr = np.array(gnu[snp_sample][:])\n",
    "    gnr = gnr.astype(str)\n",
    "    \n",
    "    pos = positions[bial_]\n",
    "    pos = pos[maf_flt]\n",
    "    pos = pos[loc_unlinked]\n",
    "    pos = pos[snp_sample]\n",
    "    prefix = f'{chrom}_'\n",
    "    pos_string = [prefix + p for p in pos.astype(str)]\n",
    "\n",
    "    gnr[gnr == '-1'] = '00' #convert missing alleles \n",
    "    dat = np.empty([gnr.shape[0], gnr.shape[1]])\n",
    "\n",
    "    #join genotypes in same individual \n",
    "    print(f\"Converting to .dat {_set} {loc} {yr} {sp} {chrom}\")\n",
    "    for x in range(gnr.shape[0]):\n",
    "        for y in range(gnr.shape[1]):\n",
    "            dat[x,y] = ''.join(gnr[x,y])\n",
    "\n",
    "    #convert to .dat format genotypes \n",
    "    dat = dat.astype(str)\n",
    "    dat_convert_dict = {'0.0':'0101',\n",
    "                        '1.0':'0102',\n",
    "                        '2.0':'0103',\n",
    "                        '3.0':'0104',\n",
    "                        '10.0':'0201',\n",
    "                        '11.0':'0202',\n",
    "                        '12.0':'0203',\n",
    "                        '13.0':'0204',\n",
    "                        '20.0':'0301',\n",
    "                        '21.0':'0302',\n",
    "                        '22.0':'0303',\n",
    "                        '23.0':'0304',\n",
    "                        '30.0':'0401',\n",
    "                        '31.0':'0402',\n",
    "                        '32.0':'0403',\n",
    "                        '33.0':'0404'}\n",
    "    ## convert values to FSTAT .dat format\n",
    "    dat = replace_with_dict2_generic(dat, dat_convert_dict, assume_all_present=False)\n",
    "    \n",
    "    #stack population name and transposed genotypes \n",
    "    popnames = np.repeat(f\"{_set}{loc}{yr}{sp}{chrom}\", gnr.shape[1])\n",
    "    dat = np.column_stack((popnames, dat.T)) #\n",
    "    #write out .dat file for LDNe \n",
    "    with open(f'../data/dat/{_set}.{loc}.{yr}.{sp}.{chrom}.dat', 'w') as datfile:\n",
    "        datfile.write(f'{gnr.shape[1]}\\t{gnr.shape[0]}\\t4\\t2\\n')\n",
    "        datfile.write(\"\\n\".join(\"\".join(map(str, x)) for x in pos_string)) \n",
    "        datfile.write(\"\\n\")\n",
    "        datfile.write(\"\\n\".join(\"\\t\".join(map(str, x)) for x in dat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------ LDNe_Ag -------------------------------\n",
      "\n",
      "Storing metadata in data/Phase3.LDNe.tsv\n",
      "\n",
      "Producing LDNe input for Luanda, 2009, coluzzii, 3L. 81 individuals, (gambcolu filter)\n",
      "GenotypeArray shape before pruning - (366186, 81, 2)\n",
      "iteration 1 retaining 49487 removing 316699 variants\n",
      "Converting to .dat AG1000G-AO Luanda 2009 coluzzii 3L\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'map'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-131-86f71cabe67f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m                         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"\\nProducing LDNe input for {loc}, {yr}, {sp}, {chrom}. {nmeta3.shape[0]} individuals, (gambcolu filter)\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m                         \u001b[0mconvert2dat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpositions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchrom\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m                     \u001b[0;31m#write metadata file for samples that are included\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-130-c988e67cfb64>\u001b[0m in \u001b[0;36mconvert2dat\u001b[0;34m(gn, positions, n, _set, loc, yr, sp, chrom)\u001b[0m\n\u001b[1;32m    116\u001b[0m                         '33.0':'0404'}\n\u001b[1;32m    117\u001b[0m     \u001b[0;31m## convert values to FSTAT .dat format\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m     \u001b[0mdat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdat_convert_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m     \u001b[0;31m#stack population name and transposed genotypes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'map'"
     ]
    }
   ],
   "source": [
    "for chrom in chroms:\n",
    "\n",
    "    print(f\"------------------------ LDNe_Ag -------------------------------\\n\")\n",
    "    print(f\"Storing metadata in data/Phase3.LDNe.tsv\")\n",
    "    #with open('../data/Phase3.LDNe.tsv', 'w') as metafile:\n",
    "    #    metafile.write(\"sample_set\\tlocation\\tyear\\tspecies\\tchromosome\\n\")\n",
    " \n",
    "        \n",
    "    #filter the gff3 to be coding and regulatory regions\n",
    "    df = allel.gff3_to_dataframe(f\"{argsgff}\")\n",
    "    coding_reg_df = df[~df.type.isin(['chromosome', 'three_prime_UTR','five_prime_UTR',\n",
    "                    'mRNA', 'CDS', 'exon'])].drop(columns=['source', 'strand', 'phase', 'score'])\n",
    "    coding_reg_df = coding_reg_df[coding_reg_df.seqid == chrom]\n",
    "\n",
    "    for _set in all_sets:\n",
    "    \n",
    "        #subset metadata\n",
    "        metadata = manifest[manifest.sample_set == _set].reset_index(drop=True)\n",
    "\n",
    "        ### loop through combos \n",
    "        for loc in metadata.location.unique():\n",
    "\n",
    "            nmeta = metadata[metadata.location == loc]\n",
    "\n",
    "            for yr in nmeta.year.unique():\n",
    "\n",
    "                nmeta2 = nmeta[nmeta.year == yr]\n",
    "                \n",
    "                #have edited .species_gambiae_coluzzii column to contain arabiensis instead of NA \n",
    "                for sp in nmeta2.species_gambiae_coluzzii.unique():\n",
    "                    \n",
    "                    # if file exists ignore and skip\n",
    "                    myfile = Path(f\"../data/dat/{_set}.{loc}.{yr}.{sp}.{chrom}.dat\")\n",
    "                    if myfile.is_file():\n",
    "                        continue\n",
    "\n",
    "                    #if there is less than 9 samples than skip\n",
    "                    if (nmeta2.species_gambiae_coluzzii == sp).sum() <= 8:\n",
    "                        continue\n",
    "                    \n",
    "                    #need to implement separate site filters for arabiensis v gamb_colu \n",
    "                    if sp == 'arabiensis':  \n",
    "                        geno, positions = load_arrays_noncoding_and_centromeres(local_path,_set, chrom, coding_reg_df, sitefilter='arab')\n",
    "                        #filter to species \n",
    "                        nmeta3 = nmeta2[nmeta2.species_gambiae_coluzzii == sp]\n",
    "                        flt = np.array(nmeta3.index)\n",
    "                        #filter to correct loc, year, species individuals\n",
    "                        gn = geno.take(flt, axis=1)\n",
    "                        \n",
    "                        print(f\"\\nProducing LDNe input for {loc}, {yr}, {sp}, {chrom}. {nmeta3.shape[0]} individuals, (arabiensis filter)\")\n",
    "                        convert2dat(gn, positions, n, _set, loc, yr, sp, chrom)\n",
    "                \n",
    "                    else:\n",
    "                        geno, positions = load_arrays_noncoding_and_centromeres(local_path, _set, chrom, coding_reg_df, sitefilter='gamb_colu')\n",
    "                        #filter to species \n",
    "                        nmeta3 = nmeta2[nmeta2.species_gambiae_coluzzii == sp]\n",
    "                        flt = np.array(nmeta3.index)\n",
    "                        #filter to correct loc, year, species individuals\n",
    "                        gn = geno.take(flt, axis=1)   \n",
    "                        \n",
    "                        print(f\"\\nProducing LDNe input for {loc}, {yr}, {sp}, {chrom}. {nmeta3.shape[0]} individuals, (gambcolu filter)\")\n",
    "                        convert2dat(gn, positions, n, _set, loc, yr, sp, chrom)\n",
    "                        \n",
    "                    #write metadata file for samples that are included\n",
    "                    with open('../data/Phase3.LDNe.tsv', 'a') as metafile:\n",
    "                        metafile.write(f'{_set}\\t{loc}\\t{yr}\\t{sp}\\t{chrom}\\n')\n",
    "                    \n",
    "                    #write batch file for LDNe \n",
    "                    print(\"Writing .batch.txt file for LDNe...\")\n",
    "                    with open(f'../analysis/LDNe/batch/{_set}.{loc}.{yr}.{sp}.{chrom}.batch.txt', 'w') as batch_file:\n",
    "                        batch_file.write(f'1\\t0\\n1\\n0.05\\t-1\\n15\\t0\\t1\\n1\\n0\\n0\\n0\\n0\\nanalysis/LDNe/Ag_LDNe_{_set}.{loc}.{yr}.{sp}.{chrom}.out\\n')\n",
    "                        batch_file.write(f\"data/dat/{_set}.{loc}.{yr}.{sp}.{chrom}.dat\\n\")\n",
    "                        batch_file.write(\"*\")\n",
    "                        batch_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Biallelic and MAF 0.05 filter\n",
    "ac = gn.count_alleles()\n",
    "bial_ = ac.is_biallelic()\n",
    "gn = gn.compress(bial_, axis=0)\n",
    "ac = gn.count_alleles()\n",
    "\n",
    "freqs = ac.to_frequencies().compute()\n",
    "ALT1 = freqs[:,1] > 0.05\n",
    "ALT2 = freqs[:,2] > 0.05\n",
    "ALT3 = freqs[:,3] > 0.05\n",
    "maf_flt = np.logical_or(ALT1, ALT2, ALT3)\n",
    "gn = gn.compress(maf_flt, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"allel allel-DisplayAs2D\"><span>&lt;GenotypeDaskArray shape=(366186, 81, 2) dtype=int8&gt;</span><table><thead><tr><th></th><th style=\"text-align: center\">0</th><th style=\"text-align: center\">1</th><th style=\"text-align: center\">2</th><th style=\"text-align: center\">3</th><th style=\"text-align: center\">4</th><th style=\"text-align: center\">...</th><th style=\"text-align: center\">76</th><th style=\"text-align: center\">77</th><th style=\"text-align: center\">78</th><th style=\"text-align: center\">79</th><th style=\"text-align: center\">80</th></tr></thead><tbody><tr><th style=\"text-align: center; background-color: white; border-right: 1px solid black; \">0</th><td style=\"text-align: center\">0/0</td><td style=\"text-align: center\">0/0</td><td style=\"text-align: center\">0/0</td><td style=\"text-align: center\">0/0</td><td style=\"text-align: center\">0/0</td><td style=\"text-align: center\">...</td><td style=\"text-align: center\">0/2</td><td style=\"text-align: center\">0/0</td><td style=\"text-align: center\">0/0</td><td style=\"text-align: center\">0/0</td><td style=\"text-align: center\">0/0</td></tr><tr><th style=\"text-align: center; background-color: white; border-right: 1px solid black; \">1</th><td style=\"text-align: center\">0/0</td><td style=\"text-align: center\">0/2</td><td style=\"text-align: center\">0/2</td><td style=\"text-align: center\">0/2</td><td style=\"text-align: center\">0/2</td><td style=\"text-align: center\">...</td><td style=\"text-align: center\">0/0</td><td style=\"text-align: center\">0/0</td><td style=\"text-align: center\">0/2</td><td style=\"text-align: center\">0/2</td><td style=\"text-align: center\">2/2</td></tr><tr><th style=\"text-align: center; background-color: white; border-right: 1px solid black; \">2</th><td style=\"text-align: center\">2/2</td><td style=\"text-align: center\">2/2</td><td style=\"text-align: center\">2/2</td><td style=\"text-align: center\">2/2</td><td style=\"text-align: center\">2/2</td><td style=\"text-align: center\">...</td><td style=\"text-align: center\">0/2</td><td style=\"text-align: center\">2/2</td><td style=\"text-align: center\">2/2</td><td style=\"text-align: center\">2/2</td><td style=\"text-align: center\">2/2</td></tr><tr><th style=\"text-align: center; background-color: white; border-right: 1px solid black; \">...</th><td style=\"text-align: center\" colspan=\"12\">...</td></tr><tr><th style=\"text-align: center; background-color: white; border-right: 1px solid black; \">366183</th><td style=\"text-align: center\">1/1</td><td style=\"text-align: center\">1/1</td><td style=\"text-align: center\">1/1</td><td style=\"text-align: center\">0/1</td><td style=\"text-align: center\">1/1</td><td style=\"text-align: center\">...</td><td style=\"text-align: center\">1/1</td><td style=\"text-align: center\">0/1</td><td style=\"text-align: center\">1/1</td><td style=\"text-align: center\">1/1</td><td style=\"text-align: center\">1/1</td></tr><tr><th style=\"text-align: center; background-color: white; border-right: 1px solid black; \">366184</th><td style=\"text-align: center\">0/0</td><td style=\"text-align: center\">0/0</td><td style=\"text-align: center\">0/2</td><td style=\"text-align: center\">0/0</td><td style=\"text-align: center\">0/0</td><td style=\"text-align: center\">...</td><td style=\"text-align: center\">2/2</td><td style=\"text-align: center\">0/0</td><td style=\"text-align: center\">0/0</td><td style=\"text-align: center\">0/0</td><td style=\"text-align: center\">0/0</td></tr><tr><th style=\"text-align: center; background-color: white; border-right: 1px solid black; \">366185</th><td style=\"text-align: center\">2/2</td><td style=\"text-align: center\">2/2</td><td style=\"text-align: center\">2/2</td><td style=\"text-align: center\">0/2</td><td style=\"text-align: center\">2/2</td><td style=\"text-align: center\">...</td><td style=\"text-align: center\">2/2</td><td style=\"text-align: center\">0/2</td><td style=\"text-align: center\">2/2</td><td style=\"text-align: center\">2/2</td><td style=\"text-align: center\">2/2</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "<GenotypeDaskArray shape=(366186, 81, 2) dtype=int8>"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GenotypeArray shape before pruning - (366186, 81, 2)\n",
      "iteration 1 retaining 49487 removing 316699 variants\n"
     ]
    }
   ],
   "source": [
    "## LD pruning\n",
    "print(f\"GenotypeArray shape before pruning - {gn.shape}\")\n",
    "gnu, loc_unlinked = ld_prune(gn, size=500, step=250, threshold=.2, n_iter=1, blen=10000)\n",
    "\n",
    "#take random sample of n SNPs \n",
    "snp_sample = np.random.choice(gnu.shape[0], n, replace=False)\n",
    "snp_sample.sort()\n",
    "gnr = np.array(gnu[snp_sample][:])\n",
    "gnr = gnr.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "boolean index did not match indexed array along dimension 0; dimension is 14651815 but corresponding boolean dimension is 366186",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-123-0ce026459a12>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpositions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbial_\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mpos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpos\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmaf_flt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mpos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpos\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mloc_unlinked\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mpos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpos\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msnp_sample\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprefix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf'{chrom}_'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/apps/anaconda3/envs/NeAg/lib/python3.8/site-packages/allel/model/ndarray.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m   3410\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3411\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3412\u001b[0;31m         \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3413\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mslice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEllipsis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3414\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: boolean index did not match indexed array along dimension 0; dimension is 14651815 but corresponding boolean dimension is 366186"
     ]
    }
   ],
   "source": [
    "pos = positions[bial_]\n",
    "pos = pos[maf_flt]\n",
    "pos = pos[loc_unlinked]\n",
    "pos = pos[snp_sample]\n",
    "prefix = f'{chrom}_'\n",
    "pos_string = [prefix + p for p in pos.astype(str)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "gnr[gnr == '-1'] = '00' #convert missing alleles \n",
    "dat = np.empty([gnr.shape[0], gnr.shape[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting to .dat AG1000G-AO Luanda 2009 coluzzii 3L\n"
     ]
    }
   ],
   "source": [
    "#join genotypes in same individual \n",
    "print(f\"Converting to .dat {_set} {loc} {yr} {sp} {chrom}\")\n",
    "for x in range(gnr.shape[0]):\n",
    "    for y in range(gnr.shape[1]):\n",
    "        dat[x,y] = ''.join(gnr[x,y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['0101', '0103', '0103', ..., '0103', '0103', '0303'],\n",
       "       ['0101', '0101', '0102', ..., '0102', '0101', '0101'],\n",
       "       ['0101', '0103', '0101', ..., '0101', '0101', '0101'],\n",
       "       ...,\n",
       "       ['0102', '0102', '0102', ..., '0202', '0102', '0102'],\n",
       "       ['0103', '0101', '0101', ..., '0101', '0101', '0103'],\n",
       "       ['0103', '0101', '0101', ..., '0101', '0103', '0101']],\n",
       "      dtype='<U32')"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "replace_with_dict2_generic(dat, dat_convert_dict, assume_all_present=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert to .dat format genotypes \n",
    "dat = dat.astype(str)\n",
    "dat_convert_dict = {'0.0':'0101',\n",
    "                    '1.0':'0102',\n",
    "                    '2.0':'0103',\n",
    "                    '3.0':'0104',\n",
    "                    '10.0':'0201',\n",
    "                    '11.0':'0202',\n",
    "                    '12.0':'0203',\n",
    "                    '13.0':'0204',\n",
    "                    '20.0':'0301',\n",
    "                    '21.0':'0302',\n",
    "                    '22.0':'0303',\n",
    "                    '23.0':'0304',\n",
    "                    '30.0':'0401',\n",
    "                    '31.0':'0402',\n",
    "                    '32.0':'0403',\n",
    "                    '33.0':'0404'}\n",
    "## convert values to FSTAT .dat format\n",
    "#dat.map(dat_convert_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

Building DAG of jobs...
Using shell: /bin/bash
Provided cores: 1 (use --cores to define parallelism)
Rules claiming more threads will be scaled down.
Job counts:
	count	jobs
	1	all_ldne
	32	create_batch_file
	32	run_ldne
	65

[Sun Apr 12 15:03:42 2020]
rule create_batch_file:
    output: analysis/LDNe/batch/ag_batch_KE_3R.txt
    jobid: 49
    wildcards: pop=KE, chrom=3R

[Sun Apr 12 15:03:42 2020]
Finished job 49.
1 of 65 steps (2%) done

[Sun Apr 12 15:03:42 2020]
rule run_ldne:
    input: data/dat/KE_3R.dat, analysis/LDNe/batch/ag_batch_KE_3R.txt
    output: analysis/LDNe/Ag_LDNe_KE_3R.out
    log: logs/ldne/KE_3R.log
    jobid: 16
    wildcards: pop=KE, chrom=3R

Terminating processes on user request, this might take some time.
[Sun Apr 12 20:49:57 2020]
Error in rule run_ldne:
    jobid: 16
    output: analysis/LDNe/Ag_LDNe_KE_3R.out
    log: logs/ldne/KE_3R.log (check log file(s) for error message)
    shell:
        ~/apps/NeEstimator/Ne2-1L c:analysis/LDNe/batch/ag_batch_KE_3R.txt 2> logs/ldne/KE_3R.log
        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)

Removing output files of failed job run_ldne since they might be corrupted:
analysis/LDNe/Ag_LDNe_KE_3R.out
Complete log: /home/sanj/ag1000g/Ne_Ag/.snakemake/log/2020-04-12T150341.667304.snakemake.log

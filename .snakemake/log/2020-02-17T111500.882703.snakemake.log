Building DAG of jobs...
Using shell: /bin/bash
Provided cores: 1 (use --cores to define parallelism)
Rules claiming more threads will be scaled down.
Job counts:
	count	jobs
	1	Zarr_to_LDNe
	1

[Mon Feb 17 11:15:01 2020]
rule Zarr_to_LDNe:
    input: ../data/ag1000g.phase2.ar1.pass/, ../data/reference/Anopheles-gambiae-PEST_BASEFEATURES_AgamP4.12.gff3, ../data/samples.meta.txt
    output: data/dat
    log: logs/Zarr_to_LDNe/Zarr_to_LDNe.log
    jobid: 0

[Mon Feb 17 11:15:02 2020]
Error in rule Zarr_to_LDNe:
    jobid: 0
    output: data/dat
    log: logs/Zarr_to_LDNe/Zarr_to_LDNe.log (check log file(s) for error message)
    shell:
        python analysis/scripts/Zarr_to_LDNe.py -n 10000 --chroms 3L 3R --zarr ../data/ag1000g.phase2.ar1.pass/ --gff ../data/reference/Anopheles-gambiae-PEST_BASEFEATURES_AgamP4.12.gff3 --samples ../data/samples.meta.txt 2> logs/Zarr_to_LDNe/Zarr_to_LDNe.log
        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)

Shutting down, this might take some time.
Exiting because a job execution failed. Look above for error message
Complete log: /home/sanj/ag1000g/Ne_Ag/.snakemake/log/2020-02-17T111500.882703.snakemake.log
